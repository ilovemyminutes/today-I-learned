# Day 18. Seq2Seq, Beam Search, BLEU | 주재걸 교수님

> Seq2Seq

Seq2Seq?

- Many-to-many 문제를 해결할 수 있는 모델로 NMT를 수행할 수 있음
- Encoder와 Decoder가 포함된 것이 구조의 가장 큰 특징
- 개량된 모델은 Attention을 활용하고, Seq2Seq with Attention이라고 부름

기본 Seq2Seq 모델 구조 살펴보기

![seq2seq_no_attention](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/seq2seq_no_attention.jpg?raw=true)

- 위 그림과 같이 크게 Encoder, Decoder, 둘 사이의 thought vector로 구성
- 시퀀스 데이터가 입력됨에 따라 인코더의 hidden state가 생성되고, 인코더의 마지막 hidden state는 디코더의 h_0로 입력됨
  - 인코더의 마지막 hidden state: 입력된 시퀀스가 지닌 총체적인 의미가 함축되어 있는 벡터
  - 마지막 hidden state'만' 사용 시 문제: 시퀀셜한 학습이 진행됨에 따라 한참 앞선 시퀀스 정보가 흐려질 수 있는데, 가장 마지막 hidden state만 활용하면 이를 캐치해내지 못할 수 있다. => 그렇기 때문에 ***Seq2Seq with Attention***을 활용하는 것!
  - 문제 해결
    - 입력 데이터를 역순으로 입력하여 앞선 정보를 반영하는 일종의 트릭 활용
    - Attention 구조를 활용한 개량형 Seq2Seq
- 인코더와 디코더는 gradient vanishing 문제에서 탈피한 LSTM 모델 채택 
- 인코더의 입력 데이터는 시퀀스 끝에 \<EoS>(End of Sentence) 토큰이 포함되고, 디코더의 경우 시퀀스의 가장 앞에는 \<SoS>(Start of Sentence), 시퀀스 끝에 \<EoS>(End of Sentence) 토큰이 포함
  - 디코딩 과정에서는 \<EoS>가 등장할 경우 generating 혹은 inference가 종료됨

Attention을 활용한 Seq2Seq 살펴보기

![seq2seq_yes_attention](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/seq2seq_yes_attention.jpg?raw=true)

- 기본 Seq2Seq 구조의 마지막 hidden state만 활용하여 발생하는 문제를 해결한 모델
- Attention 구조를 추가한 것이 가장 핵심 특징
- 학습 과정
  1. 인코딩 과정까지는 기본 Seq2Seq과 같음
  2. 디코더로 넘어가는 과정에서 디코더의 hidden state 벡터를 인코더의 모든 step의 hidden state 벡터와 내적. 이렇게 내적을 통해 구한 스칼라를 Attention Score라고 부름
  3. Attention Score에 Softmax를 취하여 확률화
  4. 각각의 확률값을 각 인코딩 hidden state의 가중치로 삼아 가중합 hidden state를 산출
  5. 구한 가중합 hidden state을 바탕으로 현재의 디코더 hidden state를 구함
  6. 역전파를 통해 인코더와 디코더의 weight를 업데이트하여 학습

Seq2Seq 모델의 학습 기법

- Teacher forcing
  - Language model 특성 상 특정 step에서 모델을 통해 생성된 output은 다음 step의 input으로 활용됨
  - 따라서 첫 단어가 예측이 원활하게 되지 않으면, 총체적으로 번역이 잘못될 수 있고, 학습 초기에는 이러한 잘못된 예측이 빈번한 문제가 있음
  - 학습 초기 단계에 효율적인 학습을 위해 활용하는 방법이 Teacher forcing
  - 모델을 통해 생성된 output을 input으로 활용하는 것이 아니라, 각 input에 ground truth를 넣는 방법
  - 학습 초기에 Teacher forcing을 활용한 뒤, 어느 정도 성능을 갖추면 원칙적인 학습을 진행하게 됨
- 참고: 모델의 robustness를 위해 모델의 output을 input으로 활용하는 과정에서 sampling 방법을 활용하는 경우도 있음
  - 단지 확률이 가장 높은 단어를 출력하는 것이 아니라, 그럴 듯한 몇 개의 후보군을 갖춰 놓고, 그 중에서 random sampling하여 다음 step의 input으로 사용
  - 더 다채로운 번역이 가능하도록 학습을 유도할 수 있다고 함

Attention 기법

![attention_variants_1](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/attention_variants_1.jpg?raw=true)

- 기본적인 dot 활용 기법과 더불어, Weight 텐서를 가미한 general, concat 방법이 있음
- 내적만을 활용한 dot방법과 달리, general, concat 방법은 ***trainable한 파라미터***가 있다는 것이 핵심 특징 => 세밀한 attention이 가능하겠지

![attention_variants_2](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/attention_variants_2.jpg?raw=true)

- dot
  - 인코더의 각 hidden state와 디코더의 특정 step hidden state의 내적을 활용하는 가장 기본적인 방법
- general
  - 인코더의 각 hidden state와 가중 텐서, 그리고 디코더의 hidden state를 곱하는 형태
  - Weight Matrix의 성분은 인코더와 디코더의 hidden state 간 내적을 수행함에 있어 일종의 가중치 역할을 하게 되며, element의 구성에 따라 인코더와 디코더의 hidden state 간 상호 관계적 의미를 담을 수도 있다
  - 학습 과정에서 trainable한 파라미터가 포함되므로, 더 정교한 attention을 구현할 수 있음
- concat
  - 인코더와 디코더의 hidden state를 fully connected layer에 연결한 뒤, 또 한번의 Linear Layer에 투과시켜 내적값에 대한 의미를 포함한 단일 스칼라를 생성
  - 학습 과정에서 trainable한 파라미터가 포함되어 더 정교한 attention을 구현할 수 있다는 점에서 general 방법과 같은 맥락

> Beam Search

Greedy decoding

- 현 시점에서 가장 그럴듯한 단어를 추론해내는 것
- 가장 그럴듯한 단어를 추론했지만, 최종 출력된 문장을 보았을 때 말이 되지 않을 수 있는 가능성 존재

![beam_search_1](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/beam_search_1.jpg?raw=true)

- 가장 이상적인 그림은, 현재는 가능성이 떨어질 수 있지만, 총체적으로는 가장 그럴듯한 문장을 만들어내는 것

  ![beam_search_2](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/beam_search_2.jpg?raw=true)

  - 하지만 가장 치명적인 문제는, 이러한 총체적 확률 계산을 위해서는 연산량이 많아진다는 것
    - 사이즈가 V인 Vocabulary를 바탕으로 길이가 T인 문장을 만드려면 V^T의 연산이 필요 => 현실적으로 불가능한 지수 단위 연산
    - 이를 융통성 있게 해결한 방법이 바로 Beam Search!

Beam Search

![beam_search_3](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/beam_search_3.jpg?raw=true)

- 이상적인 것을 좀더 현실적으로, ***가장 그럴듯한 k개의 시나리오만을 고려***
- 예시를 보면 이해가 더 빠르다. 예시부터 보자

![beam_search_4](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/beam_search_4.jpg?raw=true)

- 위 그림과 k=2로 설정했다면, 매 step 마다 2개의 그럴듯한 시나리오를 선별

- 각 시나리오(후보군)마다 또다시 k개 만큼 시나리오를 그려보고, 새로운 시나리오 총 k^2=4개 중 또 다시 k=2개를 선별

- 각 후보군별로 \<EoS> 토큰이 등장하면 해당 시나리오에 대한 문장은 완성된 셈

- 종료 시점?

  1. 사용자가 사전에 설정한 길이 T에 도달하면 각 후보군은 생성을 멈춤

  2. 사용자가 사전에 설정한 완성된 문장 수에 도달하면 모델은 생성을 멈춤

  - 추려낸 후보 문장들 중 가장 그럴듯한 문장을 최종 문장으로 inference

> BLEU

알고갑시다: Precision, Recall, F-measure

![BLEU_1](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/BLEU_1.jpg?raw=true)

- Precision: '*체감*'
  - 사용자 입장에서 예측된 결과를 받아보았을 떄, 얼마나 예측되었는지 얼마나 정확한지 점쳐볼 수 있는 척도
  - 즉, 예측된 결과에 초점을 맞추어 척도를 매김
- Recall: *'이면'*
  - 사용자 입장에서는 쉽게 알아채기 어려운, 예측을 했어야했는데 예측하지 못한 것이 어느 정도 인지 가늠할 수 있는 척도
  - 즉, 실제 ground truth에 초점을 맞추어 척도를 매김
- 'I love this movie very much'를 한국어로 번역한다고 생각해보자
  - '나는 이 영화가 많이 좋다'로 번역되었을 경우
    - 'very'에 해당하는 '정말'이 번역이 되지 않았으나, 번역의 품질은 양호 -> Precision의 입장에서는 패널티를 주지 않음
    - Recall의 입장에서는 번역했어야 한 것이 번역되지 않았으므로 패널티 부여
  - '너는 이 영화가 많이 좋다'
    - 아예 번역이 잘못되 케이스로, Precision에서도 패널티를 부여하게 됨
- F-measure
  - Precision과 Recall 척도를 조화평균한 값
  - 조화평균: 더 낮은 값이 높은 가중을 두는 성질이 있음

랭귀지 모델에 단순한 평가 척도는 적용이 어렵다

![BLEU_2](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/BLEU_2.jpg?raw=true)

- 위 그림이 극명하게 잘못 점수 매겨진 경우에 해당
- model 2에 의한 예측 결과는 아예 말이 안되는 문장이나, precision, recall, f-measure 측면에서는 100% 정확도로 측정
- 언어의 특성으로 인해 발생한 문제 => BLEU라는 새로운 척도를 고안하여 해결

BLEU

![BLEU_3](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/BLEU_3.jpg?raw=true)

- 1, 2, 3, 4-Gram에 대한 precision을 구하여 매기는 평가 방법
- 번역 결과를 '번역의 품질'의 시각에서 바라보기 위해 precision을 활용
- 실제 문장의 길이와 예측된 문장 길이의 비의 term을 추가하여 recall의 취지를 함의
- 알아야 할 단점:
  - gram 단위로 점수를 측정하기 때문에 시퀀스 길이가 애초에 짧을 경우 점수가 현저히 낮게 측정될 수 있음
  - 번역의 품질이 현저히 낮거나 높은 경우에 대해서는 적절한 측정이 가능하나, 애매하게 번역된 경우에는 올바른 측정이 되지 않을 수 있음

![BLEU_4](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/BLEU_4.jpg?raw=true)

- 단순 지표만 활용했을 때 최고 성능을 기록했던 문장이, BLEU를 적용하고 나니 0점으로 집계된 모습. 훨씬 fair한 점수 집계가 가능!