# Day 19. Transformer | 주재걸 마스터

> Transformer

RNN(LSTM, GRU)을 개선하기 위한 몸부림

- Bidirectional
  - LSTM, GRU, Vanilla RNN 등의 hidden state를 시퀀스 순방향으로만 넣는 것이 아닌 역방향의 hidden state를 추가 학습하여 시퀀스 정보를 더욱 다채롭게 파악하는 방법
  - 하지만, 태생적으로 (어느 정도 해결했다 하더라도) long-term dependency에 대한 문제가 존재

Transformer

- *Attention is All You Need*: 논문 제목만으로도 알 수 있듯, 기존 RNN의 학습 방식을 아예 갈아 엎은 모델
- 순서에 구애 받지 않는 Self-attention 메커니즘을 통해 RNN의 long-term dependency 문제를 해결
- Self Attention 메커니즘을 통해 RNN 모델보다 빠르고 고성능 학습 가능
- Seq2Seq의 구조와 같이 인코더와 디코더를 활용하나, 세부적인 학습 절차는 아주 다름.
  - LSTM, GRU 등의 RNN 셀을 활용하는 Seq2Seq과 달리, Transformer는 오로지 Attention 메커니즘만을 활용. *Attention is All You Need!*

Transformer: Self-Attention

![transformer_self_attention_1](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/transformer_self_attention_1.jpg?raw=true)

- Remind: Attention of Seq2Seq
  
  - 인코더의 모든 time step에서의 hidden state를 참조하기 위해 디코더의 hidden state와 내적을 진행
- Self-Attention도 Seq2Seq의 Attention 과정과 목적이 같다: 입력된 정보를 좀더 다채롭게 바라보기 위함
  
  - 왜 *'Self-Attention'*이냐? 입력된 데이터 자체로부터 Attention 값을 구해내기 때문이라고 개념적으로 받아들이면 되겠다
- Process: 입력된 데이터 x_i의 Attention을 구하는 과정
  1. 입력된 모든 x_m에 대해 Query, Key, Value 벡터를 생성.
     - Query, Key, Value 벡터는 input vector에 Wq, Wk, Wv의 Weight Matrix를 곱하여 구함
     - Query: '다른 input들의 중요도를 알고 싶어'의 쿼리문을 작성하는 뉘앙스로 이해하자
     - Key: '다른 input들의 중요도는 이러해'의 쿼리문에 대응되는 키값을 리스트업한 것으로 이해하자
     - Value: '중요도는 구체적으로 이런 값이야'의 Attention 값을 구하기 위해 활용되는 밸류로 이해하자
  2. x_i의 Query와 (자기 자신을 포함한) 모든 Key와의 내적 연산을 수행한 뒤, 가중치로 활용하기 위해 Softmax 레이어에 투과
     - 실제로는 Key를 한데 모은 Key Matrix와 Queery를 행렬곱하여 일괄 계산
     - Query, Key, Value 각각 trainable한 파라미터를 지니고 있기 때문에 자기 자신에 대한 중요도를 높게 파악하는(=학습에 도움이 안되는) 상황을 예방할 수 있음 => 다른 입력 벡터에 더 높은 가중을 부여할 수 있게 됨
  3. 각 소프트맥스를 앞서 각 단어별로 생성한 Value 벡터에 스칼라배한 뒤, summation(가중합)
     - 실제로는 소프트맥스 벡터와 Value Matrix의 행렬곱으로 진행됨

- 수식으로 살펴보기

  ![transformer_self_attention_4](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/transformer_self_attention_2.jpg?raw=true)

  - Attention값을 구하는 과정을 수식으로 표현하면 위 그림과 같음

  - 특정 입력 단어의 쿼리 벡터(q)와 모든 키 벡터(k_i)와의 내적 연산 후, 소프트맥스를 취해준 뒤, 이를 가중치로 삼아 밸류 벡터(v_i)를 가중합하여 Attention울 구하는 형태

  - 좀더 확장하자면, 쿼리 행렬과 키 행렬을 행렬곱한 뒤, 소프트맥스를 취하고 밸류 행렬과 행렬곱

    - 그림으로 표현하자면 아래 그림과 같음

      ![transformer_self_attention_5](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/transformer_self_attention_5.jpg?raw=true)

      - 쿼리 행렬과 키 행렬의 행렬곱 결과: 하나의 행이 '하나의 쿼리와 각 키벡터의 내적값을 담은 벡터'
      - 소프트맥스값을 지닌 행렬과 밸류 행렬의 행렬곱 연산: '밸류 행렬의 각 행에 대해 해당 위치의 소프트맥스 성분값을 스칼라곱하는 것'

- 스케일링

  ![transformer_self_attention_6](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/transformer_self_attention_6.jpg?raw=true)

  - 원활한 학습을 위해서는 위 수식의 제곱근(차원)으로 값을 나누어 주어야 한다.

  - 왜? 분포가 왜곡되기 때문!

  - 가령, 각 쿼리와 키 벡터의 성분이 평균이 0, 분산이 1이고 각 성분이 독립이라고 가정한 것을 생각해보자.

    ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+Query+%3D+%28q_%7B1%7D%2C+...%2C+q_%7Bn%7D%29)

    ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+Key+%3D+%28k_%7B1%7D%2C+...%2C+k_%7Bn%7D%29)

    두 벡터 간 내적을 수행하면

    ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+Query+%5Ccdot+Key+%3D+q_%7B1%7Dk_%7B1%7D+%2B+...+%2B+q_%7Bn%7Dk_%7Bn%7D)

    가정에 의해 내적값은 평균이 0, 분산이 n인 분포를 갖게 된다. 즉, 내적 결과 분산이 증가했다.

  - 내적값은 이후 소프트맥스값으로 활용하게 되는데, 분산이 크면 소프트맥스 각 성분이 큰 값에 편중되는 경향으로 gradient vanishing의 위험이 발생한다.

  - 그렇기 때문에, 다시 스케일을 맞춰주기 위해 Normalize를 진행, 즉 제곱근(분산)으로 모든 값을 나눈 뒤 소프트맥스를 취한다

Multi-headed Attention: 집단지성은 옳다

- Transformer에서는 입력된 단어를 더욱 다차원적으로 바라보기 위해 여러 쌍의 Attention을 활용 - *Multi-Head*

![multi_attn_1](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/multi_attn_1.jpg?raw=true)

- 즉, 학습 파라미터인 Wq, Wk, Wv 쌍을 여러 개 만들어 여러 개의 Attention을 생성한 뒤, 모든 Attention을 고려하여 output을 도출

  ![multi_attn_2](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/multi_attn_2.jpg?raw=true)

- 위 그림과 같이 여러 Attention 행렬을 Concat한 뒤, Linear 레이러를 거쳐 모든 의미가 함축된 최종 Attention 행렬을 도출. 이를 활용하여 output을 생성

- Self Attention의 시간복잡도

  ![multi_attn_3](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/multi_attn_3.jpg?raw=true)

  - Self Attention 연산량은 Vocabulary Size(n)를 제곱한 값과 쿼리·키·밸류 벡터의 차원(d)의 곱에 비례
    - 쿼리 행렬(n x d)과 키 행렬(d x n)의 연산 과정이 있기 때문
  - Vocabulary Size가 커질 수록 RNN 모델에 비해 연산량이 커지지만, 핵심은 *병렬 연산이 가능*하다는 것
  - 시퀀스 데이터를 순차적으로 입력받아 hidden state를 도출하는 식이 아닌, 각 단어에 대해 단발적 계산이 진행되므로, GPU 환경이 풍부하다면 O(1)의 시간복잡도를 확보
  - 또한, RNN의 경우 첫 hidden state에서 마지막 hidden state에 미치기까지 n번의 거리가 발생하나, Self Attention을 활용하면 순서에 구애받지 않기 떄문에 거리가 1
  - 즉, 컴퓨터 환경만 확실하다면 RNN보다 Transformer의 학습 과정이 훨씬 빠르다

Layer Normalization

- 추가적인 이해가 필요하다...
- [?] Affine Transformation

Positional Encoding

- Self Attention으로 할 수 없는 것: 출력한 단어들에 대해 순서를 매길 수 없음

- 때문에, Positional Encoding을 통해 순서 정보를 추가적으로 얻음

  ![positional_encoding_1](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/positional_encoding_1.jpg?raw=true)

- 순서 정보는 특정한 스칼라로 표현하는 것이 아닌, 벡터로서 표현하며, 각 성분은 sin, cos의 주기 함수로 표현된다.

- 순서 벡터를 기존의 임베딩 벡터에 더해줌으로써 순서 정보를 반영하게 됨!

  ![positional_encoding_2](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/positional_encoding_2.jpg?raw=true)

- 순서 벡터는 위 그림과 같이 표현되고, 각 위치가 *유일하게(unique)* 표현됨

Transformer: Warm-up Learning Rate Scheduler

- iteration에 따라 learning rate를 높게 또는 낮게 조정하면 효율적인 학습이 가능해짐

- 일반적으로, 비교적 낮은 iteration에서는 높은 learning rate를 주다가 높은 iteration에서는 낮는 learning rate를 부여

- Transformer 또한 휴리스틱하게 learning rate 조정 스케줄이 마련되어 있음

  ![lr_scheduler](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/lr_scheduler.jpg?raw=true)

Decoder

![decoder](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/decoder.jpg?raw=true)

- 인코더는 '번역하기 전 시퀀스'의 패턴을 파악하는 역할을, 디코더는 '번역한 후 시퀀스'의 패턴을 파악하는 역할을 수행

- 디코더는 크게 (1)Masked Multi-Head Attention -> (2)Multi-Head Attention -> Feed Forward의 순서대로 진행되고, 단계 간에는 Residual Connection이 존재

- (1) Masked Multi-Head Attention: *치팅 방지!*

  - Remind: 디코더는 '번역한 후 시퀀스'의 패턴을 파악하는 역할을 수행. 즉, '정답'에 대한 패턴을 파악하는 역할을 수행

  - 당연하게도, 학습 과정에서 미래에 등장할 단어까지 포함하여 패턴을 파악하는 것은 잘못된 학습

  - 그렇기 때문에, 미래에 등장할 정답 단어를 가려두고 학습을 진행하는데, 이러한 방법이 바로 Masked Multi-Head Attention

    ![mask](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/mask.jpg?raw=true)

  - 위 그림은 Attention을 구하는 과정에서 쿼리와 키의 내적을 구해 소프트맥스를 취한 결과(현재 시점: \<SOS>토큰)

  - \<SOS>를 생성하는 시점에 '나는', '집에' 토큰은 미래에 등장하는 토큰. 따라서 중요도 측정 대상에서 제외

  - 해당 위치의 측정된 중요도를 모두 0처리한 뒤, 다시 소프트맥스를 취함으로써 마스킹!

- (2) Multi-Head Attention: *인코더야 인코더야, 지금까지의 결과는 이런데, 다음에는 어떤 단어가 나와야 하니?*

  - 가장 주목할 점은, 밸류와 키는 인코더로부터 구한 Attention을, 쿼리는 디코더의 이전 레이어 output을 사용한다는 점
  - Remind: Query: '다른 input들의 중요도를 알고 싶어'의 쿼리문을 작성하는 뉘앙스로 이해하자
  - 즉, 디코더의 현황을 바탕으로 다른 단어 간 연관성을 파악하기 위해 기존 인코더의 Attention을 참조

성능: SOTA

![benchmark](https://github.com/iloveslowfood/iloveTIL/blob/main/boostcamp_ai/etc/images/week04/benchmark.jpg?raw=true)

- BLEU가 최고치가 100인 것을 감안하면 매우 낮은 성능으로 보일 수 있지만, 그렇지 않음
- 가령, 난 영화를 좋아해의 정답이 "I love this movie"인데 "I like this movie"로 번역된 경우처럼 의미는 맞지만 출력한 단어가 잘못되어 점수가 하락하는 경우가 다수
- 이러한 수치가 나온 것은 매우 높은 것!