# Day 15. Generative Models | 최성준 교수님

> Generative Models: Basic

*What is a generative model?*

- 무언가를 생성해내는 것만이 generative model의 전부가 아님

Learning a Generative Model

- 가령 강아지를 생성한다면 다음을 할 수 있음
  - Generation: ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+x_%7Bnew%7D+%3D+%5Csim+p%28x%29)를 따르는 강아지같이 생긴새로운 x(new)를 샘플링할 수 있음 <- 흔히 생각할 수 있는 케이스
    - implicit generative model: 입력이 주어졌을 때 생성을 할 수 있는 모델
  - Density estimation: p(x) 값이 높으면 강아지, 그렇지 않으면 강아지가 아님. <- 이상치 탐색(anomly detection)이 가능
    - expicit generative model: Generation + 입력이 주어졌을 때 입력에 대한 확률값을 얻어낼 수 있는 모델
  - Unsupervised representation learning: 입력된 이미지들이 공통적으로 어떤 특성을 지니고 있는지 학습 <- feature learning
  - 그렇다면, ***p(x)는 어떻게 구할것인가?***

P(x)를 어떻게 구하는지 살펴봅시다

- 잠시 몇 가지 확률 분포를 짚고 넘어갑시다
  - 베르누이 분포
    - Note. 2가지의 사건이 있으나 이 확률분포를 표현하는 파라미터는 1개
  - 카테고리 분포
    - Note. M가지의 사건이 있으나 이 확률분포를 표현하는 파라미터는 M-1개

- 하나의 컬러 이미지 픽셀에 대해 RGB 결합확률분포를 구한다고 생각해보자
  - ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+%28r%2C+g%2C+b%29+%5Csim+p%28R%2C+G%2C+B%29) 
  - 나올 수 있는 경우의수: 256 × 256 × 256
  - 필요한 파라미터 수: (256 - 1) × (256 - 1) × (256 - 1)
  - 핵심: 단 하나의 픽셀을 표현하기 위해 **필요한 파라미터 수가 지나치게 많다**
- '*흠.. 그러면 바이너리 이미지 픽셀에 대해 결합확률분포를 구해보면 더 낫지 않을까?*'
  - 각 픽셀에 대해 나올 수 있는 경우의 수: 2(0 또는 1)
  - 전체 이미지에 대해 본다면 n개의 픽셀에 대한 카테고리 분포라고 볼 수 있겠지
    - 따라서 전체 이미지에 대해 필요한 파라미터수는 ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+2%5E%7Bn%7D+-+1) => 여전히 파라미터 수가 많아
- *'너무 많아. 더 줄여보자'*
  - 위 바이너리 이미지의 카테고리 분포에 대해 각 사건 간 독립을 가정하면 다음을 만족
    ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+p%28x_%7B1%7D%2C+x_%7B2%7D%2C...%2Cx_%7Bn%7D%29+%3D+p%28x_%7B1%7D%29p%28x_%7B2%7D%29%5C%2C...%5C%2Cp%28x_%7Bn%7D%29)
  - 사건의 경우의 수: ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+2%5E%7Bn%7D) (기존과 같음)
  - 필요한 파라미터 수: n (독립성을 가정하니 확 줄어듦)

Conditional Independence

- 독립성을 가정하면 파라미터 수가 확 줄어들지만 현실적으로 말이 안되는 가정인데... 조건부 독립을 적용해보자. 다음의 핵심 개념을 활용

  - Chain rule: ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+p%28x_%7B1%7D%2C+x_%7B2%7D%2C+...%2C+x_%7Bn%7D%29+%3D+p%28x_%7B1%7D%29p%28x_%7B2%7D+%7C+x_%7B1%7D%29p%28x_%7B3%7D%7Cx_%7B1%7D%2C+x_%7B2%7D%29...p%28x_%7Bn%7D%7Cx_%7B1%7D%2C+...%2C+x_%7Bn-1%7D%29) 
  - Bayes' rule: ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+p%28x+%7Cy%29+%3D+%5Cfrac+%7Bp%28x%2C+y%29%7D%7Bp%28y%29%7D+%3D+%5Cfrac+%7Bp%28y%7Cx%29p%28x%29%7D+%7Bp%28y%29%7D)
  - Conditional independence: ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+if+x+%5Cbot+y+%7C+z%2C+then+p%28x%7Cy%2C+z%29+%3D+p%28x%7Cz%29)

- Chain rule에 의해 앞선 바이너리 이미지에 대한 분포는 다음과 같이 유도(독립성과 무관)
  ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+p%28x_%7B1%7D%2C+x_%7B2%7D%2C+...%2C+x_%7Bn%7D%29+%3D+p%28x_%7B1%7D%29p%28x_%7B2%7D+%7C+x_%7B1%7D%29p%28x_%7B3%7D%7Cx_%7B1%7D%2C+x_%7B2%7D%29...p%28x_%7Bn%7D%7Cx_%7B1%7D%2C+...%2C+x_%7Bn-1%7D%29)

- 각 항마다 필요한 파라미터 수는 1개, 2개, 4개, ...

  - 필요한 파라미터는 총 ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+2%5E%7Bn%7D+-+1) 으로 이전과 변하지 않음(당연하지 어떤 조건도 없는데)

- 위의 chain rule에 마르코프 가정을 곁들이면 파라미터 수를 확 줄일 수 있다!

  - Markov assumption: i+1번째 확률변수는 i번째 확률변수와 dependent, 나머지 1, ..., i-1번째 확률변수와는 independent

  - 이를 가정하면 ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+p%28x_%7B1%7D%2C+x_%7B2%7D%2C+...%2C+x_%7Bn%7D%29+%3D+p%28x_%7B1%7D%29p%28x_%7B2%7D+%7C+x_%7B1%7D%29p%28x_%7B3%7D%7Cx_%7B1%7D%2C+x_%7B2%7D%29...p%28x_%7Bn%7D%7Cx_%7B1%7D%2C+...%2C+x_%7Bn-1%7D%29) 는 다음과 같이 축소됨

    ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+p%28x_%7B1%7D%2C+...%2C+x_%7Bn%7D%29+%3D+p%28x_%7B1%7D%29p%28x_%7B2%7D+%7C+x_%7B1%7D%29...p%28x_%7Bn%7D%7Cx_%7Bn-1%7D%29)

  - 필요한 파라미터 수는 총 2n-1개로 지수 단위에서 polynomial 단위로 감소

  - 이러한 조건부 독립성을 활용한 방법을 ***Auto-regressive model***이라 부름

    - 주의! 꼭 마르코프 가정과 같이 이전 항과의 dependency일 때만 auto-regressive model이라 부르는 것이 아니라, 나머지 모든 항과의 dependency 가정 등 이러한 dependency의 가정을 포함한 모델 전반을 auto-regressive model라고 부름
    - 일반적으로 이전의 1개 항을 고려하는 모델을 AR(1), 이전의 N개 항을 고려하는 모델을 AR(N)으로 표기

Auto-regressive Model

- 예) 28 × 28 바이너리 이미지 
  - 최종 목적은 각 이미지로부터 어떠한 확률값을 얻는 것:
    ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+p%28x%29+%3D+p%28x_%7B1%7D%2C+x_%7B2%7D%2C+...%2C+x_%7B784%7D%29%2C+x+%5Cin+%5C%7B0%2C+1%5C%7D%5E%7B784%7D) 
  - Chain Rule을 활용하여 p(x)를 고안할 수 있음: ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+p%28x_%7B1%3A784%7D%29+%3D+p%28x_%7B1%7D%29p%28x_%7B2%7D%7Cx_%7B1%7D%29...p%28x_%7B784%7D%7Cx_%7B1%7D%2C...%2Cx_%7B783%7D%29)
    - 이미지의 픽셀의 순서를 매기는 방식에 따라 모델의 성능이 달라짐
    - 몇 개의 항까지 dependency를 주느냐에 따라 모델의 성능이 달라짐

NADE: Neural Autoregressive Density Model Estimator

<img src="https://github.com/iloveslowfood/iloveCookBook/blob/main/boostcamp_ai/etc/images/week03/NADE.png?raw=true" />

- 가정: i번째 픽셀은 1, ... , i-1번째 픽셀과 dependent (AR(n-1))
- 가정에 따른 i번째 픽셀의 확률분포: ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+p%28x_%7Bi%7D+%7C+x_%7B1%3Ai-1%7D%29+%3D+%5Csigma%28%5Calpha+_%7Bi%7D+%5Ctextbf+%7B%5Ctextrm+h%7D_%7Bi%7D+%2B+b_%7Bi%7D%29%5C%2C+where%5C%2C+%5Ctextbf+%7B%5Ctextrm+h%7D_%7Bi%7D+%3D+%5Csigma%28W_%7B%3Ci%7D+x_%7B1%3Ai-1%7D+%2B+%5Ctextbf%7B%5Ctextrm+c%7D%29)
- 모델의 특성
  - 입력 데이터의 density를 계산할 수 있는 explicit model
  - auto-regressive modle로서 정의된 확률분포에 의해 각 이미지에 대한 확률값을 얻을 수 있음
  - 바이너리 픽셀이 아닌 continuous 픽셀인 경우, mixture of Gaussian을 활용하여 확률값을 얻을 수 있음

PixelRNN <- 아직 이해가 잘 안됨

> Generative Models: Practical

Variational Auto-encoder, VAE

- Variational inference(VI)

  - posterior distribution을 찾는 것이(또는 근접한 분포를 찾는) 핵심!
  - posterior distribution을 알아내는 것이 불가능한 경우가 많이 때문에 variational distribution을 최적화
  - KL Divergence를 최소화함으로써 최적의 variational distribution을 찾게 됨

  ![image-20210205203536883](https://github.com/iloveslowfood/iloveCookBook/blob/main/boostcamp_ai/etc/images/week03/VAE.jpg?raw=true)

- 한계

  - Auto-encoder는 엄밀하게는 Generative Model이 아님

  - prior fitting term은 KL Divergence term이 포함되어 기본적으로 미분이 가능해야 하기 때문에 latent prior distribution에 대해 다양한 가정이 어려움

    - 따라서 Latent prior distribution에 대해 가우시안 분포(특히 isotropic 가우시안 분포)를 가정하는 경우가 많음

      ![image-20210205204002936](https://github.com/iloveslowfood/iloveCookBook/blob/main/boostcamp_ai/etc/images/week03/VAE2.png?raw=true)

  - 모델이 얼마나 그럴싸한지 알기 어려우며, explicit model이 아님

  - 인코더 활용시 prior fitting term이 KL Divergence를 활용해 분포 가정에 한계가 명확함

- 생성된 결과물은 이런 식

  ![image-20210205194134953](C:\Users\iloveslowfood\Documents\workspace\iloveCookBook\boostcamp_ai\etc\images\week03\VAE3)

Adversarial Auto-encoder, AAE

- VAE의 한계 극복: KL Divergence에 있는 prior fitting term을 GAN object로 대체
- 가우시안 분포를 사전확률분포로 가정하지 않아도 구할 수가 있어짐
  - 즉, 임의의 latent distribution을 사전확률분포로 활용할 수 있음
- Wasserstein Auto-encoder: AAE가 사실은 Latent Distribution과 Prior Distribution 사이의 Wasserstein Distance를 좁혀주는 것과 같다는 것을 증명함
- Generation 성능이 일반적으로 VAE보다 좋음

Generative Adversarial Network, GAN

- *Discriminator vs. Generator*

  - 진짜같은 이미지를 생성하는 Generator와 이미지의 진위를 판별하는 Discriminator의 공존으로 Generation 성능을 높여나감

- 핵심 장점: 결과를 내뱉는 Generator에 대해 학습하며 성능이 점점 좋아지는 Discriminator가 있다는 것

  - 덩달아 Generator도 학습이 잘 될 수 있음
  - implicit model

- GAN vs. VAE

  ![image-20210205195505026](C:\Users\iloveslowfood\Documents\workspace\iloveCookBook\boostcamp_ai\etc\images\week03\GAN)

  - VAE: 입력 데이터 x를 인코더를 거쳐 latent space로 보내고 디코더를 통해 x로 되돌리는 과정을 통해 학습
  - GAN:
    - latent space에서 출발
    - Generator를 통해 Fake를 생성
    - 생성된 이미지에 대해 진위를 판별하는 classifier Discriminator를 학습 ... (1)
    - Discriminator가 True를 뱉을 수 있도록 Generator를 업데이트 ... (2)
    - (1)과 (2)를 반복 - *minimax game*

- 학습 원리

  - Discriminator

    ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+max_%7BD%7D+V%28G%2C+D%29+%3D+E_%7B%5Ctextbf+%7B%5Ctextrm+%7Bx%7D%7D+%5Csim++p_%7Bdata%7D%7D%5BlogD%28%5Ctextrm+x%29%5D+%2B+E_%7B%5Ctextrm+x+%5Csim+p_%7BG%7D%7D%5Blog%281+-+D%28%5Ctextrm+x%29%29%5D)

    에 대하여 V를 최대화 하는 D는 ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+D%5E%7B%2A%7D_%7BG%7D%28%5Ctextrm+x%29+%3D+%5Cfrac+%7Bp_%7B%5Ctextrm+data%7D%28%5Ctextrm+x%29%7D+%7Bp_%7B%5Ctextrm+data%7D%28%5Ctextrm+x%29+%2B+p_%7BG%7D%28%5Ctextrm+x%29%7D) 

  -  Generator

    ![](https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+min_%7BG%7D+V%28G%2C+D%29+%3D+E_%7B%5Ctextrm+%7Bx%7D+%5Csim+p_%7Bdata%7D+%7D%5Blog+D%28%5Ctextrm+%7Bx%7D%29%5D+%2B++E_%7B%5Ctextrm+%7Bx%7D+%5Csim+p_%7BG%7D+%7D%5Blog+%281+-+D%28%5Ctextrm+%7Bx%7D%29%29%5D)

    에 대하여 다음을 얻을 수 있음

    ![image-20210205201107818](C:\Users\iloveslowfood\Documents\workspace\iloveCookBook\boostcamp_ai\etc\images\week03\GAN2)
    - 즉, JS Divergence를 최소화하는 것이 목적이 됨
    - BUT! 실제로 봤을 떄 Discriminator가 수렴한다는 보장도 없고, Generator도 학습이 잘 된다는 보장도 없기 때문에 조금 애매한 부분이 있다고... 하지만 좀더 봐야겠다

DCGAN

![image-20210205201451711](C:\Users\iloveslowfood\Documents\workspace\iloveCookBook\boostcamp_ai\etc\images\week03\DCGAN)

- Generator는 Deconvolution 레이어가, Discriminator는 Convolution 레이어가 활용됨



Info-GAN

![image-20210205201712486](C:\Users\iloveslowfood\Documents\workspace\iloveCookBook\boostcamp_ai\etc\images\week03\InfoGAN)

- Generator를 통해 *c*의 보조 클래스를 생성
  - Generation을 할 때 GAN이 특정 모드에 집중할 수 있도록 하는 효과

Text2Image

- 텍스트를 이미지로 생성

Puzzle-GAN

- 패치를 여러개 추출한 뒤, 이를 다시 재조합하여 원래의 이미지로 복원하는 방법

CycleGAN

![image-20210205202057009](C:\Users\iloveslowfood\Documents\workspace\iloveCookBook\boostcamp_ai\etc\images\week03\CycleGAN)

- 꼭 알아야할 개념: cycle-consistency loss
- 2가지 도메인(말과 얼룩말 등)에 대한 학습이 가능(말을 얼룩말로 바꿔준다거나)

Star-GAN

![image-20210205202304420](C:\Users\iloveslowfood\Documents\workspace\iloveCookBook\boostcamp_ai\etc\images\week03\StarGAN)

- 이미지의 도메인을 바꿔주는 CycleGAN과 달리 사용자가 모드를 조작하여 생성이 가능

Progressive-GAN

![image-20210205202349930](C:\Users\iloveslowfood\Documents\workspace\iloveCookBook\boostcamp_ai\etc\images\week03\ProgressiveGAN)

- 고차원 이미지를 잘 만들 수 있는 방법
- 레이어 크기를 점점 늘려가는 것이 모델의 핵심 특징

> Attituede & Tips

- GAN은 generative 방법론 중의 하나일 뿐!
- 개요를 이해하자

- Density Estimation은 AR 모델을 이야기하는 경우가 많음
- 시간날 때 읽어보자! [Durk Kingma](http://dpkingma.com/)
- High-level view

- 아이디어 가져가기!
- 실무적인 면에서 코드는 가독성이 중요하고, 연구적인 면에서는 코드를 밑바닥까지 이해하는 것이 중요
- 논문 읽을 때 Introduction에 주목할 것
  - 논문의 중간 생략 과정을 알기 위해서는 직접 구현해봐야 한다
- 실력이 좋다는 것: 구현을 잘한다 or 이론적 이해가 강하다 아이디어가 풍성한 것은 (아직) 실력으로 반영되었다고 볼 수 없음