# 당근마켓

### Recruitment Process

서류전형 > 화상면접 > 직무면접 > 컬쳐핏면접

- 서류전형: 자유 형식
- 화상면접: 포지션 관련 지식. 약 30분
- 직무면접: 직무역량, 경험에 대해 깊이 이야기. 1시간
- 컬쳐핏: 당근마켓이 추구하는 문화와 맞는지

### Main Positions

> ML 엔지니어 | 2021.02.07

주요 업무

- Recommendation: *NLP, Clustering*
  - 추천 후보 모델: 실시간으로 100만개이상의 글 중 다음 볼 글을 예측
  - 추천 랭킹 모델: 실시간으로 200개 이상의 글 중 가장 관심 가질 글을 예측
  - 지역 추천 모델: 사용자 군집화로 초기 사용자에게 다양한 인기글 추천
- Classification: *NLP*
  - 글 분류 모델: 글의 모든 컨텐츠를 입력으로 신고/제재 등 예측
  - 제목 카테고리 예측: 카테고리를 선택 편리를 위해 제목을 입력하면 카테고리 예측
  - 채팅 메세지 분류 (개발 중): 주소, 전화번호, 욕설/성희롱 등 예측
  - FAQ 분류 예측: 고객 문의가 FAQ에 해당하는지 예측하여 답변 효율화
- Representation: *NLP, BERT, Embedding, CV*
  - 글 이해 모델 : BERT 기반으로 이미지, 텍스트, 숫자 등 피쳐로 사전 학습하여 글 컨텐츠 이해
  - 글 이미지 인덱스 : 1억 건 이상 글 이미지 중 가장 유사한 이미지를 사용하는 글 검색
  - 유사 고객 문의 인덱스 : 비슷한 고객 문의 글을 검색하여 답변 효율화
  - 당근이 프로필 도용 방지 : 당근이 프로필 이미지를 사용하면 삭제 후 알림
  - 관련 글 찾기 : word2vec 모델 기반으로 글에 대해 임베딩 학습
- Ranking: *NLP*
  - 검색 고도화/개인화 (개발 중) : 단순 형태소 분석의 검색을 사용자 패턴에 맞게 검색 품질 고도화
  - 광고 타겟팅 (예정) : 사용자가 더 관심있을 광고를 우선 노출
- Graph: *NLP, Embedding, Network Analysis*
  - 사용자 예측 (예정) : 적절한 사용자 타겟을 선택하여 광고 또는 서비스 제공
  - 관계 예측 시스템 (예정) : 글, 사용자, 업체 간 관계를 예측하여 더 적절한 서비스 제공
  - 글 임베딩 (예정) : 관련 글 찾기를 더욱 고도화
  - 사용자 임베딩 (예정) : 개인화 추천/검색 고도화

세부 포지션

- Experiment
  - 4 GPUs * 2대의 워크스테이션을 Kubernetes로 구성하여 **Kubeflow 기반 학습**, **하이퍼파라미터 튜닝**
  - Google Cloud에서 선점형 GPU/TPU를 사용하여 대규모 학습
- Production
  - 파이프라인 시스템: GCP에서 **Kubeflow Pipelines 설치운영** 중
  - 데이터 수집: BigQuery에 기록되는 클라이언트/서버 **데이터를 쿼리**
  - 데이터 전처리: Cloud Dataflow에서 Apache Beam을 활용하여 대용량 **분산 처리**
  - 서빙: 분산 확장 처리 가능한 gRPC **서버 개발**
  - 배포: 사내 SRE팀에 Kubernetes 배포 요청, 함께 운영/관리

관심 분야

- Kubeflow: 당근마켓의 ML 시스템은 모두 클라우드 환경에서 동작. 구글 Kubernetes 엔진에 Kubeflow를 배포해 모델 train. Kubeflow를 활용한 ML 시스템 구축
- Self-Supervised Learning: 데이터가 빠르게 증가함에 따라 레이블이 없는 대량의 데이터를 활용하는 방법 필요. 당근마켓 서비스 품질 저하 방지. 
  - Self-Supervised Learning에 대한 높은 이해, 구현
  - Multi GPU 또는 분산 학습 경험
  - 모델 학습 속도/자원 프로파일링 분석
  - 학습 데이터/모델 예측 분석

> 데이터 엔지니어(플랫폼 부문) | 2021.02.07

- 주요 업무
  - 당근마켓 글로벌 서비스의 데이터 파이프라인 개발
  - 데이터 인프라/웨어하우스 구축
  - 가용성 높고 확장 가능한 데이터 아키텍처 설계
- 자격 요건: *빅데이터 프레임워크, 분산 데이터, 컨테이너 오케스트레이션 시스템, 클라우드, 시각화*
  - Hadoop MR, Hive, Spark, Flink, Presto 등 빅데이터 프레임워크 사용 경험
  - 분산 환경에서 대용량 데이터 처리/실시간 데이터 처리 경험
  - Kubernetes 등 컨테이너 오케스트레이션 시스템 운영 경험
  - AWS, GCP 등 클라우드 환경에서 IaC를 사용한 데이터 인프라 설계 및 운용 경험
  - Tableau 등을 이용한 데이터 시각화 경험

### Posts

> [풋내기 창업자의 스타트업 창업하기 12화_채용하기 | 2021.11.03](https://medium.com/daangn/%ED%92%8B%EB%82%B4%EA%B8%B0-%EC%B0%BD%EC%97%85%EC%9E%90%EC%9D%98-%EC%8A%A4%ED%83%80%ED%8A%B8%EC%97%85-%EC%B0%BD%EC%97%85%ED%95%98%EA%B8%B0-11%ED%99%94-%EC%B1%84%EC%9A%A9%ED%95%98%EA%B8%B0-f919e45032f)

**요약: 일처럼 생각하지 않고 즐기는 사람이 좋다!**

- 상황에 따라 채용 고려 요인이 달라짐: 규모가 작으면 제너럴리스트, 규모 크면 프로페셔널리스트
- 대면 면접의 한계 극복을 위해 포지션별 과제를 냄 - 과제 결과에 따라 70% 이상 당락 결정
  - 문제에 얼마나 '몰입'하고, 어떻게 '해결'했느냐. 즉, 과제 동안 얼마나 즐겼느냐?

> [이미지 분류 모델 AutoML 파이프라인 | 2020.12.08](https://medium.com/daangn/%EC%9D%B4%EB%AF%B8%EC%A7%80-%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8-automl-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-68beb1ff15bf)

**요약: 어떤 코딩도 없이 데이터 처리, 모델 평가/배포. 유지보수 업무 최소화. AutoML 너무 좋다!**

- 2020 3분기 구글 클라우드 AutoML을 활용한 이미지 분류 모델 개발 및 파이프라인 자동화

  - 이미지 필터링 목적
  - “특정 분야(이미지 인식 포함)는 이미 AutoML이 머신러닝 전문가 보다 훨씬 뛰어난 모델을 만들고 있다” - Jeff Dean
  - 당사 또한 향후 AutoML에 대해 긍정적
  - 구글 클라우드 AutoML, Vision Edge: 학습한 모델을 파일로 내보내 사용 가능 => 트래픽에 비례한 추가 비용이 들지 않음 => 서비스 활용 적극 검토!

- 구글 클라우드 AutoML

  - 데이터셋만 구성하면 자동으로 모델 구성, 쉬운 배포
  - 장점
    - 편리한 데이터셋 관리: 이미지 라벨링 기능, 중복 사진 자동 필터링
    - 학습 전 모델 속도, 패키지 크기 예상 가능: Trade-off에 따라 학습할 모델 선택 가능
    - 좋은 모델 Evaluation UI: Confidence score에 따른 Precision, Recall 확인, Confusion Matrix 등
    - 다양한 내보내기 옵션: TFLite, Container(TF Saved Model) 등

- 데이터셋 만들기 전략

  - 운영 부서와 협업: 운영 업무 중 발견되는 이미지 지속 추가
  - 키워드 검색(feat. 게시글 검색 기능): 검색을 통해 선정적 이미지 추리기
  - 유사 이미지 사용: 유사 이미지 인덱싱
  - 유사 게시글 사용: "함께 봤어요" 활용
  - AutoML 연동: 구글 클라우드 Storage, AutoML, Client 활용

  - ML 어드민을 활용해 42000개 이미지에 대한 데이터 구축에 2일 정도 걸림

- 모델 배포

  - TF Lite 모델 배포에 Firebase 활용: 연동성 굿! 클릭만으로 배포 가능
  - TF Serving AWS EKS 배포 후 서비스 즉시 적용: 0.5CPU, 500Mb 메모리 리소스에서 80ms의 예측 속도

- 파이프라인 자동화

  - 최초에 데이터셋을 대량으로 구축하고 이후 데이터 지속 추가: 지속적인 학습 및 배포 요구
  - 파이프라인에 포함되지 않은 데이터는 ML어드민 WebServer의 Periodic Task 사용

- Kubeflow 파이프라인 구성

  - Train: AutoML에 훈련 시작 명령 전송
  - Evaluation: 신규 모델과 기준 모델의 Precision, Recall을 비교해 Threshold 이상 하락하면 배포 중단
    - 성능 1%p 하락: 알림 발송
    - 성능 3%p 하락: 배포 중단, 파이프라인 에러 처리
  - Client Deployment: Firebase에 배포된 모델을 최신 모델로 교체. 배포 모델 타입은 TFLite
  - Server Deployment: AutoML에서 TF Saved Model로 모델 export 후, S3에 업로드. AWS EKS에 배포된 TF Serving을 Restart
    - Garbage Collection: 학습된 AutoML 모델과 Export된 파일은 일정 기간 후 삭제

### Reference

- [Google Cloud AutoML](https://cloud.google.com/automl)
- [TensorFlow Lite](https://www.tensorflow.org/lite?hl=ko)
  - [Keras 모델 변환](https://www.tensorflow.org/lite/convert?hl=ko#convert_a_keras_model_)