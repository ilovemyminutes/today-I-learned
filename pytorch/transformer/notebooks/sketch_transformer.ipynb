{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('py36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e4583e3e051816b4ac89cf1b6baba6f81196736b754b6f0341f1424c68064e5b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from attention import MultiHeadAttention\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from positional_encoding import PositionalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data: list) -> (list, int):\n",
    "    max_len = len(max(data, key=len))\n",
    "    output = [sample + [0]*(max_len-len(sample)) for sample in tqdm(data)]\n",
    "    return output, max_len\n",
    "\n",
    "VOCAB_SIZE = 100\n",
    "data = [\n",
    "  [62, 13, 47, 39, 78, 33, 56, 13, 39, 29, 44, 86, 71, 36, 18, 75],\n",
    "  [60, 96, 51, 32, 90],\n",
    "  [35, 45, 48, 65, 91, 99, 92, 10, 3, 21, 54],\n",
    "  [75, 51],\n",
    "  [66, 88, 98, 47],\n",
    "  [21, 39, 10, 64, 21],\n",
    "  [98],\n",
    "  [77, 65, 51, 77, 19, 15, 35, 19, 23, 97, 50, 46, 53, 42, 45, 91, 66, 3, 43, 10],\n",
    "  [70, 64, 98, 25, 99, 53, 4, 13, 69, 62, 66, 76, 15, 75, 45, 34],\n",
    "  [20, 64, 81, 35, 76, 85, 1, 62, 8, 45, 99, 77, 19, 43]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 9, 8, 4, 5, 0, 3, 0, 1, 4],\n",
       "        [8, 5, 4, 1, 7, 8, 2, 6, 1, 0],\n",
       "        [4, 8, 9, 2, 4, 6, 0, 4, 2, 1],\n",
       "        [8, 7, 3, 2, 3, 3, 4, 0, 9, 7],\n",
       "        [8, 4, 2, 5, 4, 6, 1, 8, 4, 1],\n",
       "        [1, 0, 0, 8, 5, 5, 8, 9, 2, 2],\n",
       "        [8, 3, 6, 0, 0, 4, 8, 7, 0, 7],\n",
       "        [2, 6, 0, 8, 4, 0, 2, 3, 9, 4],\n",
       "        [6, 7, 9, 7, 4, 7, 9, 4, 5, 1],\n",
       "        [6, 6, 0, 7, 3, 9, 1, 1, 6, 6]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "torch.randint(0, 10, (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data, MAX_LEN = padding(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.FloatTensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[62., 13., 47., 39., 78., 33., 56., 13., 39., 29., 44., 86., 71., 36.,\n",
       "         18., 75.,  0.,  0.,  0.,  0.],\n",
       "        [60., 96., 51., 32., 90.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [35., 45., 48., 65., 91., 99., 92., 10.,  3., 21., 54.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [75., 51.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [66., 88., 98., 47.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [21., 39., 10., 64., 21.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [98.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [77., 65., 51., 77., 19., 15., 35., 19., 23., 97., 50., 46., 53., 42.,\n",
       "         45., 91., 66.,  3., 43., 10.],\n",
       "        [70., 64., 98., 25., 99., 53.,  4., 13., 69., 62., 66., 76., 15., 75.,\n",
       "         45., 34.,  0.,  0.,  0.,  0.],\n",
       "        [20., 64., 81., 35., 76., 85.,  1., 62.,  8., 45., 99., 77., 19., 43.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "data_tensor"
   ]
  }
 ]
}