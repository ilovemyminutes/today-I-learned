{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('py36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e4583e3e051816b4ac89cf1b6baba6f81196736b754b6f0341f1424c68064e5b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from attention import MultiHeadAttention\n",
    "from encoder import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 6\n",
    "NUM_HEADS = 2\n",
    "MAX_LEN = 4\n",
    "encoder = Encoder(d_model=6, num_heads=2, max_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = nn.LayerNorm(normalized_shape=D_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4, 1, 6]) torch.Size([4, 1, 6])\n",
      "Error\n",
      "..\\attention.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(self.d_model)\n"
     ]
    }
   ],
   "source": [
    "attn_scores = encoder(tensor_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "ln(attn_scores).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 1.0609, -0.0602, -0.0560,  0.7548,  0.6464,  0.9860]],\n",
       "\n",
       "        [[ 0.3296, -0.0277,  0.3275,  0.3069,  0.8603,  1.0444]],\n",
       "\n",
       "        [[ 0.6354,  0.2358,  0.5755,  0.8440,  0.4686,  0.7855]],\n",
       "\n",
       "        [[ 0.1682,  0.4743,  0.2788,  0.1155,  0.6572,  0.3863]]],\n",
       "       grad_fn=<AsStridedBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "attn_scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "residual.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.4888, 0.3735, 0.3462, 0.1984],\n",
       "        [0.4878, 0.9013, 0.0998, 0.2447],\n",
       "        [0.7737, 0.5993, 0.8875, 0.4567],\n",
       "        [0.7347, 0.8924, 0.2499, 0.1155]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "attn = torch.rand(4,4)\n",
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "masked_fill() received an invalid combination of arguments - got (mask=Tensor, value=int, ), but expected one of:\n * (Tensor input, Tensor mask, Tensor value)\n * (Tensor input, Tensor mask, Number value)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-76d818f9dd80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: masked_fill() received an invalid combination of arguments - got (mask=Tensor, value=int, ), but expected one of:\n * (Tensor input, Tensor mask, Tensor value)\n * (Tensor input, Tensor mask, Number value)\n"
     ]
    }
   ],
   "source": [
    "torch.masked_fill(mask=mask, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tril(torch.ones(4,4), diagonal=0).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "pad_id = 0\n",
    "vocab_size = 100\n",
    "max_len = 10\n",
    "hidden_dim = 6\n",
    "\n",
    "def padding(data: list, pad_id: int=0) -> (list, int):\n",
    "    max_len = len(max(data, key=len))\n",
    "    output = [sample + [pad_id]*(max_len-len(sample)) for sample in tqdm(data)]\n",
    "    return output, max_len\n",
    "\n",
    "data = [\n",
    "     [62, 13, 47, 39, 78, 33, 56, 13, 39, 29],\n",
    "     [60, 96, 51, 32, 90, 44, 86, 71, 36, 18],\n",
    "     [35, 45, 48, 65, 91, 99, 92, 10, 31, 21],\n",
    "     [75, 51, 45, 48, 65, 91, 99, 11, 13, 28],\n",
    "     [66, 88, 98, 47, 48, 65, 17, 13, 67, 99],\n",
    "     ]\n",
    "\n",
    "# data, max_len = padding(data)\n",
    "data = torch.LongTensor(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weight initialized\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=hidden_dim)\n",
    "embedding.weight.data.uniform_(-1, 1)\n",
    "print('Weight initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_embedded = embedding(data)\n",
    "X_embedded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_query = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Query\n",
    "w_key = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Key\n",
    "w_value = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Value\n",
    "\n",
    "query = w_query(X_embedded)\n",
    "key = w_key(X_embedded)\n",
    "value = w_value(X_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MultiHeadAttention(hidden_dim=hidden_dim, num_heads=2)\n",
    "attention_mat = attention(query, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "attention_mat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layer_norm = nn.LayerNorm(normalized_shape=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "attention_mat.size()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "attn_layer_norm(attention_mat).size()"
   ]
  }
 ]
}