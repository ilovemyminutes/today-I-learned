{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('py36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e4583e3e051816b4ac89cf1b6baba6f81196736b754b6f0341f1424c68064e5b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from attention import MultiHeadAttention\n",
    "from encoder import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 6\n",
    "NUM_HEADS = 2\n",
    "MAX_LEN = 4\n",
    "encoder = Encoder(d_model=6, num_heads=2, max_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rands = torch.rand(10, 4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "warning = torch.tensor([[[[-0.0005]],\n",
    "\n",
    "         [[-0.1330]]],\n",
    "\n",
    "\n",
    "        [[[-0.0731]],\n",
    "\n",
    "         [[-0.0796]]],\n",
    "\n",
    "\n",
    "        [[[-0.0494]],\n",
    "\n",
    "         [[-0.1368]]],\n",
    "\n",
    "\n",
    "        [[[-0.0534]],\n",
    "\n",
    "         [[-0.1086]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "warning.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[0.5331]],\n",
       "\n",
       "         [[0.4669]]],\n",
       "\n",
       "\n",
       "        [[[0.5016]],\n",
       "\n",
       "         [[0.4984]]],\n",
       "\n",
       "\n",
       "        [[[0.5218]],\n",
       "\n",
       "         [[0.4782]]],\n",
       "\n",
       "\n",
       "        [[[0.5138]],\n",
       "\n",
       "         [[0.4862]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "F.softmax(warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "torch.matmul(value, value.transpose(-1, -2)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([4, 2, 1, 1]), torch.Size([4, 2, 1, 3]))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "attn_raw.size(), value.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Value: tensor([[[[ 0.0982, -0.3208,  0.1822],\n",
      "          [-0.1967, -0.1831,  0.3248],\n",
      "          [-0.5634, -0.3581,  0.2186],\n",
      "          [-0.2450, -0.1362,  0.0016]],\n",
      "\n",
      "         [[ 0.2875, -0.3545, -0.1058],\n",
      "          [ 0.1571, -0.0165, -0.2656],\n",
      "          [ 0.4136,  0.1086, -0.5090],\n",
      "          [ 0.1277, -0.1174, -0.1879]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0548, -0.1286,  0.2920],\n",
      "          [-0.2804, -0.4597,  0.3159],\n",
      "          [-0.3840, -0.2573,  0.1385],\n",
      "          [-0.4327, -0.2655,  0.1239]],\n",
      "\n",
      "         [[ 0.0772, -0.0358,  0.1251],\n",
      "          [ 0.4670, -0.0497, -0.2630],\n",
      "          [ 0.2421,  0.0061, -0.2739],\n",
      "          [ 0.2861,  0.0898, -0.2361]]],\n",
      "\n",
      "\n",
      "        [[[-0.1011, -0.1369,  0.3023],\n",
      "          [-0.2612, -0.1382,  0.1947],\n",
      "          [-0.3280, -0.5734,  0.0681],\n",
      "          [-0.5033, -0.2594,  0.4877]],\n",
      "\n",
      "         [[ 0.1291, -0.0219, -0.0682],\n",
      "          [ 0.1201, -0.0549, -0.3217],\n",
      "          [ 0.3903, -0.2089, -0.0475],\n",
      "          [ 0.3944,  0.1730, -0.6897]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1319, -0.2355,  0.0248],\n",
      "          [-0.3025, -0.6992,  0.0878],\n",
      "          [-0.3307, -0.0410,  0.1621],\n",
      "          [-0.0796, -0.0569,  0.2487]],\n",
      "\n",
      "         [[ 0.1911, -0.3534,  0.0939],\n",
      "          [ 0.5390, -0.2713, -0.0626],\n",
      "          [ 0.0056,  0.1480, -0.1376],\n",
      "          [-0.0343, -0.0421, -0.0450]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0521, -0.0596,  0.2823],\n",
      "          [-0.3598, -0.2654,  0.0352],\n",
      "          [-0.1142,  0.0522,  0.1864],\n",
      "          [-0.1601, -0.3107,  0.2885]],\n",
      "\n",
      "         [[ 0.0163, -0.0568,  0.0174],\n",
      "          [ 0.2726,  0.0193, -0.2012],\n",
      "          [ 0.1132,  0.1072, -0.3101],\n",
      "          [ 0.3590, -0.0980, -0.3089]]],\n",
      "\n",
      "\n",
      "        [[[-0.1822,  0.0009,  0.3798],\n",
      "          [-0.4946, -0.6482,  0.1619],\n",
      "          [-0.6092, -0.5965,  0.2243],\n",
      "          [-0.1688, -0.2341,  0.2738]],\n",
      "\n",
      "         [[-0.0192,  0.1474, -0.2528],\n",
      "          [ 0.5122, -0.1389, -0.2574],\n",
      "          [ 0.6023,  0.0204, -0.4319],\n",
      "          [ 0.0676,  0.0404,  0.0707]]],\n",
      "\n",
      "\n",
      "        [[[-0.0687, -0.1655,  0.0411],\n",
      "          [-0.2326, -0.4582,  0.2111],\n",
      "          [-0.1733, -0.2955,  0.4378],\n",
      "          [-0.3845, -0.5127,  0.1880]],\n",
      "\n",
      "         [[ 0.1145, -0.1072,  0.0603],\n",
      "          [ 0.2783, -0.0853,  0.0915],\n",
      "          [ 0.2127,  0.0350, -0.1629],\n",
      "          [ 0.3505,  0.0036, -0.0353]]],\n",
      "\n",
      "\n",
      "        [[[-0.2104, -0.3079,  0.1618],\n",
      "          [-0.2102, -0.1137,  0.2186],\n",
      "          [-0.2268, -0.3827, -0.0017],\n",
      "          [-0.2248, -0.3658,  0.1126]],\n",
      "\n",
      "         [[ 0.3966, -0.0031, -0.2663],\n",
      "          [ 0.1986, -0.1200, -0.4172],\n",
      "          [ 0.3456, -0.3502, -0.2363],\n",
      "          [ 0.4473, -0.2229, -0.2813]]],\n",
      "\n",
      "\n",
      "        [[[-0.2226, -0.2989, -0.0363],\n",
      "          [-0.4632, -0.7152,  0.1738],\n",
      "          [-0.0276,  0.0151,  0.3632],\n",
      "          [-0.1140, -0.0982,  0.2347]],\n",
      "\n",
      "         [[ 0.2355, -0.2438, -0.0942],\n",
      "          [ 0.6290, -0.1022, -0.1939],\n",
      "          [ 0.0252,  0.0804, -0.1730],\n",
      "          [ 0.0373, -0.0653, -0.0984]]],\n",
      "\n",
      "\n",
      "        [[[-0.1781, -0.3407,  0.3318],\n",
      "          [-0.2107, -0.2588,  0.4098],\n",
      "          [-0.3855, -0.2943,  0.2458],\n",
      "          [-0.2269, -0.1724, -0.0745]],\n",
      "\n",
      "         [[ 0.4324, -0.1851, -0.3906],\n",
      "          [ 0.2516, -0.0600, -0.3469],\n",
      "          [ 0.1673,  0.0982, -0.1574],\n",
      "          [ 0.1098, -0.1125, -0.0500]]]], grad_fn=<TransposeBackward0>)\n",
      "SHAPE: torch.Size([10, 2, 4, 3])\n",
      "Warning: tensor([[[[-2.5199e-01, -2.1133e-01, -1.1900e-01, -1.7804e-01],\n",
      "          [-2.8195e-01, -2.1456e-01, -1.3078e-01, -1.6818e-01],\n",
      "          [-2.5109e-01, -1.6352e-01, -1.0683e-01, -1.0124e-01],\n",
      "          [-2.4057e-01, -1.6805e-01, -1.2183e-01, -1.3918e-01]],\n",
      "\n",
      "         [[-3.2860e-02, -6.3209e-02, -8.2012e-02, -8.7102e-02],\n",
      "          [-6.0701e-02, -7.8846e-02, -8.5511e-02, -7.9062e-02],\n",
      "          [-9.0225e-03,  1.3635e-02,  2.0067e-02,  9.2674e-03],\n",
      "          [ 3.2491e-02,  9.4324e-02,  1.1272e-01,  8.4249e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.0651e-02, -8.6513e-02, -1.1929e-01, -6.5119e-02],\n",
      "          [-9.5231e-02, -1.1196e-01, -1.1635e-01, -5.6648e-02],\n",
      "          [-9.4225e-02, -1.3453e-01, -1.1658e-01, -5.3695e-02],\n",
      "          [-6.1495e-02, -1.1080e-01, -8.8586e-02, -4.1269e-02]],\n",
      "\n",
      "         [[-2.7778e-02, -3.8951e-02, -3.7034e-02, -3.1734e-02],\n",
      "          [-4.2522e-02, -4.7467e-02, -5.3311e-02, -5.3360e-02],\n",
      "          [ 1.3067e-02,  2.1587e-02,  4.5308e-02,  4.1187e-02],\n",
      "          [ 5.7003e-02,  6.2347e-02,  9.4714e-02,  9.6135e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.5905e-02, -1.9662e-01, -1.9722e-01, -9.5828e-02],\n",
      "          [-1.0317e-01, -2.2751e-01, -2.3268e-01, -1.3592e-01],\n",
      "          [-9.2935e-02, -1.9285e-01, -2.0600e-01, -1.3100e-01],\n",
      "          [-8.9095e-02, -2.1216e-01, -2.2131e-01, -1.2126e-01]],\n",
      "\n",
      "         [[-2.9461e-03, -1.1478e-02, -6.7566e-03, -2.3809e-02],\n",
      "          [-4.0074e-02, -1.2921e-02, -2.2239e-02, -1.6615e-02],\n",
      "          [-1.0812e-02,  2.0084e-02,  1.1462e-02,  2.3064e-02],\n",
      "          [-8.3565e-02, -9.0803e-02, -9.4584e-02, -1.0583e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5613e-01, -1.5539e-01, -1.1114e-01, -1.7026e-01],\n",
      "          [-1.8444e-01, -1.9947e-01, -7.2202e-02, -1.7310e-01],\n",
      "          [-1.6417e-01, -2.0065e-01, -5.7026e-02, -1.3334e-01],\n",
      "          [-2.0613e-01, -2.1655e-01, -1.1775e-01, -2.0809e-01]],\n",
      "\n",
      "         [[ 3.9152e-03,  3.2646e-02,  3.1889e-02,  3.4856e-02],\n",
      "          [-2.2634e-02, -5.4901e-03, -1.2028e-02, -3.4387e-03],\n",
      "          [ 2.7125e-03,  3.6480e-02,  7.7381e-02,  5.0956e-02],\n",
      "          [-4.7746e-02, -5.1047e-02, -3.8922e-02, -4.3318e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5665e-01, -1.1094e-01, -1.0979e-01, -1.4958e-01],\n",
      "          [-1.0749e-01, -7.1999e-02, -8.5799e-02, -1.4269e-01],\n",
      "          [-1.0066e-01, -6.4129e-02, -7.2806e-02, -1.0930e-01],\n",
      "          [-1.5644e-01, -1.0434e-01, -1.0971e-01, -1.5429e-01]],\n",
      "\n",
      "         [[-5.4092e-02, -5.6738e-02, -4.1872e-02, -5.3117e-02],\n",
      "          [ 5.0852e-02,  6.7631e-02,  3.9570e-02,  5.1829e-02],\n",
      "          [-6.3277e-03, -8.7725e-03, -8.4001e-03,  1.7356e-03],\n",
      "          [-5.6489e-02, -6.8839e-02, -4.7470e-02, -4.8192e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1146e-01, -1.8878e-01, -9.1735e-02, -1.8512e-01],\n",
      "          [-2.0308e-01, -2.0719e-01, -1.0855e-01, -1.8169e-01],\n",
      "          [-1.4502e-01, -1.7706e-01, -9.9680e-02, -1.3368e-01],\n",
      "          [-1.9269e-01, -1.7598e-01, -8.7046e-02, -1.6947e-01]],\n",
      "\n",
      "         [[-1.0453e-01, -1.2918e-01, -1.3143e-01, -1.1974e-01],\n",
      "          [ 3.2627e-03, -4.5854e-03, -1.1207e-02, -5.8851e-03],\n",
      "          [ 3.0904e-02,  3.1372e-02,  2.9664e-02,  3.3586e-02],\n",
      "          [-5.9999e-02, -7.6486e-02, -7.8199e-02, -6.8579e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0019e-01, -1.0171e-01, -1.4509e-01, -1.1218e-01],\n",
      "          [-1.2720e-01, -1.3036e-01, -1.8892e-01, -1.4279e-01],\n",
      "          [-1.4615e-01, -1.5018e-01, -2.2482e-01, -1.5245e-01],\n",
      "          [-1.0992e-01, -1.2475e-01, -2.0459e-01, -1.3676e-01]],\n",
      "\n",
      "         [[ 3.0092e-02,  5.2690e-02,  6.0026e-02,  6.4414e-02],\n",
      "          [-1.0659e-02, -1.6200e-02, -1.9261e-02, -1.1780e-02],\n",
      "          [-1.2628e-01, -1.6885e-01, -1.4983e-01, -1.7277e-01],\n",
      "          [-2.5231e-02, -2.6483e-02, -1.6547e-02, -1.9189e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.3177e-02, -8.2808e-02, -9.3864e-02, -4.9425e-02],\n",
      "          [-1.3502e-01, -1.8529e-01, -2.4399e-01, -1.1758e-01],\n",
      "          [-1.4781e-01, -1.7935e-01, -2.3600e-01, -1.1575e-01],\n",
      "          [-1.0422e-01, -1.3998e-01, -1.9761e-01, -9.5212e-02]],\n",
      "\n",
      "         [[-1.3799e-02, -4.7059e-03, -1.0366e-02, -2.1822e-02],\n",
      "          [-2.3533e-04,  5.5007e-04, -4.5777e-04, -1.0189e-02],\n",
      "          [ 3.9380e-02,  6.0183e-02,  5.6027e-02,  3.1571e-02],\n",
      "          [ 5.4015e-02,  6.8386e-02,  6.9265e-02,  5.8902e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6107e-01, -1.3803e-01, -1.3170e-01, -1.4823e-01],\n",
      "          [-1.0702e-01, -1.2467e-01, -1.3524e-01, -1.2141e-01],\n",
      "          [-1.4300e-01, -9.6780e-02, -1.4679e-01, -1.6115e-01],\n",
      "          [-1.8493e-01, -1.3384e-01, -1.6033e-01, -1.8471e-01]],\n",
      "\n",
      "         [[ 8.6961e-02,  1.0188e-01,  7.8401e-02,  9.9708e-02],\n",
      "          [ 3.3515e-03,  6.1653e-03,  5.5443e-03,  7.4568e-03],\n",
      "          [-9.2387e-02, -1.0276e-01, -7.6822e-02, -9.3867e-02],\n",
      "          [-2.5311e-02, -3.0798e-02, -2.3562e-02, -2.4980e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1579e-01, -1.7191e-01, -1.8705e-01, -2.1398e-01],\n",
      "          [-1.5232e-01, -2.2224e-01, -2.1205e-01, -2.0799e-01],\n",
      "          [-1.4984e-01, -2.0543e-01, -1.6701e-01, -1.1976e-01],\n",
      "          [-1.1430e-01, -1.5431e-01, -1.3583e-01, -1.1158e-01]],\n",
      "\n",
      "         [[-2.9913e-02, -3.8125e-02, -3.4092e-02, -1.7360e-02],\n",
      "          [-9.9159e-02, -1.1210e-01, -1.2126e-01, -9.3153e-02],\n",
      "          [-6.4251e-02, -5.1180e-02, -4.2129e-02, -4.5404e-02],\n",
      "          [ 5.7553e-02,  1.0756e-01,  1.4711e-01,  9.0059e-02]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "SHAPE: torch.Size([10, 2, 4, 3])\n",
      "Attention_raw: tensor([[[[0.4454, 0.4630, 0.4908, 0.4773],\n",
      "          [0.4449, 0.4661, 0.4887, 0.4777],\n",
      "          [0.4398, 0.4558, 0.4683, 0.4724],\n",
      "          [0.4322, 0.4348, 0.4416, 0.4444]],\n",
      "\n",
      "         [[0.5546, 0.5370, 0.5092, 0.5227],\n",
      "          [0.5551, 0.5339, 0.5113, 0.5223],\n",
      "          [0.5602, 0.5442, 0.5317, 0.5276],\n",
      "          [0.5678, 0.5652, 0.5584, 0.5556]]],\n",
      "\n",
      "\n",
      "        [[[0.4868, 0.4881, 0.4794, 0.4917],\n",
      "          [0.4868, 0.4839, 0.4842, 0.4992],\n",
      "          [0.4732, 0.4610, 0.4596, 0.4763],\n",
      "          [0.4704, 0.4568, 0.4543, 0.4657]],\n",
      "\n",
      "         [[0.5132, 0.5119, 0.5206, 0.5083],\n",
      "          [0.5132, 0.5161, 0.5158, 0.5008],\n",
      "          [0.5268, 0.5390, 0.5404, 0.5237],\n",
      "          [0.5296, 0.5432, 0.5457, 0.5343]]],\n",
      "\n",
      "\n",
      "        [[[0.4818, 0.4538, 0.4525, 0.4820],\n",
      "          [0.4842, 0.4466, 0.4476, 0.4702],\n",
      "          [0.4795, 0.4470, 0.4458, 0.4616],\n",
      "          [0.4986, 0.4697, 0.4684, 0.4961]],\n",
      "\n",
      "         [[0.5182, 0.5462, 0.5475, 0.5180],\n",
      "          [0.5158, 0.5534, 0.5524, 0.5298],\n",
      "          [0.5205, 0.5530, 0.5542, 0.5384],\n",
      "          [0.5014, 0.5303, 0.5316, 0.5039]]],\n",
      "\n",
      "\n",
      "        [[[0.4601, 0.4531, 0.4643, 0.4489],\n",
      "          [0.4596, 0.4517, 0.4850, 0.4577],\n",
      "          [0.4584, 0.4410, 0.4664, 0.4541],\n",
      "          [0.4605, 0.4587, 0.4803, 0.4589]],\n",
      "\n",
      "         [[0.5399, 0.5469, 0.5357, 0.5511],\n",
      "          [0.5404, 0.5483, 0.5150, 0.5423],\n",
      "          [0.5416, 0.5590, 0.5336, 0.5459],\n",
      "          [0.5395, 0.5413, 0.5197, 0.5411]]],\n",
      "\n",
      "\n",
      "        [[[0.4744, 0.4865, 0.4830, 0.4759],\n",
      "          [0.4605, 0.4651, 0.4687, 0.4515],\n",
      "          [0.4764, 0.4862, 0.4839, 0.4723],\n",
      "          [0.4750, 0.4911, 0.4844, 0.4735]],\n",
      "\n",
      "         [[0.5256, 0.5135, 0.5170, 0.5241],\n",
      "          [0.5395, 0.5349, 0.5313, 0.5485],\n",
      "          [0.5236, 0.5138, 0.5161, 0.5277],\n",
      "          [0.5250, 0.5089, 0.5156, 0.5265]]],\n",
      "\n",
      "\n",
      "        [[[0.4733, 0.4851, 0.5099, 0.4837],\n",
      "          [0.4486, 0.4495, 0.4757, 0.4562],\n",
      "          [0.4561, 0.4481, 0.4677, 0.4583],\n",
      "          [0.4669, 0.4751, 0.4978, 0.4748]],\n",
      "\n",
      "         [[0.5267, 0.5149, 0.4901, 0.5163],\n",
      "          [0.5514, 0.5505, 0.5243, 0.5438],\n",
      "          [0.5439, 0.5519, 0.5323, 0.5417],\n",
      "          [0.5331, 0.5249, 0.5022, 0.5252]]],\n",
      "\n",
      "\n",
      "        [[[0.4675, 0.4615, 0.4489, 0.4560],\n",
      "          [0.4709, 0.4715, 0.4577, 0.4673],\n",
      "          [0.4950, 0.5047, 0.4813, 0.5051],\n",
      "          [0.4788, 0.4755, 0.4531, 0.4706]],\n",
      "\n",
      "         [[0.5325, 0.5385, 0.5511, 0.5440],\n",
      "          [0.5291, 0.5285, 0.5423, 0.5327],\n",
      "          [0.5050, 0.4953, 0.5187, 0.4949],\n",
      "          [0.5212, 0.5245, 0.5469, 0.5294]]],\n",
      "\n",
      "\n",
      "        [[[0.4802, 0.4805, 0.4791, 0.4931],\n",
      "          [0.4664, 0.4537, 0.4394, 0.4732],\n",
      "          [0.4533, 0.4404, 0.4275, 0.4632],\n",
      "          [0.4605, 0.4481, 0.4337, 0.4615]],\n",
      "\n",
      "         [[0.5198, 0.5195, 0.5209, 0.5069],\n",
      "          [0.5336, 0.5463, 0.5606, 0.5268],\n",
      "          [0.5467, 0.5596, 0.5725, 0.5368],\n",
      "          [0.5395, 0.5519, 0.5663, 0.5385]]],\n",
      "\n",
      "\n",
      "        [[[0.4383, 0.4403, 0.4477, 0.4383],\n",
      "          [0.4724, 0.4673, 0.4649, 0.4678],\n",
      "          [0.4874, 0.5015, 0.4825, 0.4832],\n",
      "          [0.4602, 0.4743, 0.4659, 0.4602]],\n",
      "\n",
      "         [[0.5617, 0.5597, 0.5523, 0.5617],\n",
      "          [0.5276, 0.5327, 0.5351, 0.5322],\n",
      "          [0.5126, 0.4985, 0.5175, 0.5168],\n",
      "          [0.5398, 0.5257, 0.5341, 0.5398]]],\n",
      "\n",
      "\n",
      "        [[[0.4785, 0.4666, 0.4618, 0.4510],\n",
      "          [0.4867, 0.4725, 0.4773, 0.4713],\n",
      "          [0.4786, 0.4615, 0.4688, 0.4814],\n",
      "          [0.4571, 0.4349, 0.4297, 0.4498]],\n",
      "\n",
      "         [[0.5215, 0.5334, 0.5382, 0.5490],\n",
      "          [0.5133, 0.5275, 0.5227, 0.5287],\n",
      "          [0.5214, 0.5385, 0.5312, 0.5186],\n",
      "          [0.5429, 0.5651, 0.5703, 0.5502]]]], grad_fn=<SoftmaxBackward>)\n",
      "SHAPE: torch.Size([10, 2, 4, 4])\n",
      "..\\attention.py:61: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(self.d_model)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "encoder(rands).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "masked_fill() received an invalid combination of arguments - got (mask=Tensor, value=int, ), but expected one of:\n * (Tensor input, Tensor mask, Tensor value)\n * (Tensor input, Tensor mask, Number value)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-76d818f9dd80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: masked_fill() received an invalid combination of arguments - got (mask=Tensor, value=int, ), but expected one of:\n * (Tensor input, Tensor mask, Tensor value)\n * (Tensor input, Tensor mask, Number value)\n"
     ]
    }
   ],
   "source": [
    "torch.masked_fill(mask=mask, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tril(torch.ones(4,4), diagonal=0).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "pad_id = 0\n",
    "vocab_size = 100\n",
    "max_len = 10\n",
    "hidden_dim = 6\n",
    "\n",
    "def padding(data: list, pad_id: int=0) -> (list, int):\n",
    "    max_len = len(max(data, key=len))\n",
    "    output = [sample + [pad_id]*(max_len-len(sample)) for sample in tqdm(data)]\n",
    "    return output, max_len\n",
    "\n",
    "data = [\n",
    "     [62, 13, 47, 39, 78, 33, 56, 13, 39, 29],\n",
    "     [60, 96, 51, 32, 90, 44, 86, 71, 36, 18],\n",
    "     [35, 45, 48, 65, 91, 99, 92, 10, 31, 21],\n",
    "     [75, 51, 45, 48, 65, 91, 99, 11, 13, 28],\n",
    "     [66, 88, 98, 47, 48, 65, 17, 13, 67, 99],\n",
    "     ]\n",
    "\n",
    "# data, max_len = padding(data)\n",
    "data = torch.LongTensor(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weight initialized\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=hidden_dim)\n",
    "embedding.weight.data.uniform_(-1, 1)\n",
    "print('Weight initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_embedded = embedding(data)\n",
    "X_embedded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_query = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Query\n",
    "w_key = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Key\n",
    "w_value = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Value\n",
    "\n",
    "query = w_query(X_embedded)\n",
    "key = w_key(X_embedded)\n",
    "value = w_value(X_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MultiHeadAttention(hidden_dim=hidden_dim, num_heads=2)\n",
    "attention_mat = attention(query, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "attention_mat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layer_norm = nn.LayerNorm(normalized_shape=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "attention_mat.size()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "attn_layer_norm(attention_mat).size()"
   ]
  }
 ]
}