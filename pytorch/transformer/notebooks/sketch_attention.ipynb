{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('py36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e4583e3e051816b4ac89cf1b6baba6f81196736b754b6f0341f1424c68064e5b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from attention import MultiHeadAttention\n",
    "from encoder import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 6\n",
    "NUM_HEADS = 2\n",
    "MAX_LEN = 4\n",
    "encoder = Encoder(d_model=6, num_heads=2, max_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.6611, 0.5318, 0.1099, 0.1732, 0.7478],\n",
       "         [0.2951, 0.4061, 0.1075, 0.8161, 0.7739],\n",
       "         [0.3400, 0.1615, 0.5076, 0.8063, 0.5073],\n",
       "         [0.5689, 0.2168, 0.3346, 0.4579, 0.3236]]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "rands = torch.rand(1, 4, 5)\n",
    "rands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.2404, 0.2113, 0.1385, 0.1476, 0.2622],\n",
       "         [0.1602, 0.1789, 0.1328, 0.2696, 0.2585],\n",
       "         [0.1725, 0.1443, 0.2040, 0.2751, 0.2040],\n",
       "         [0.2397, 0.1686, 0.1896, 0.2145, 0.1876]]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "F.softmax(rands, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[0.2481, 0.2488, 0.2543, 0.2488],\n",
       "          [0.2479, 0.2486, 0.2544, 0.2492],\n",
       "          [0.2555, 0.2496, 0.2470, 0.2479],\n",
       "          [0.2491, 0.2491, 0.2531, 0.2488]],\n",
       "\n",
       "         [[0.2537, 0.2490, 0.2487, 0.2486],\n",
       "          [0.2534, 0.2489, 0.2487, 0.2490],\n",
       "          [0.2487, 0.2525, 0.2444, 0.2544],\n",
       "          [0.2509, 0.2509, 0.2481, 0.2501]]],\n",
       "\n",
       "\n",
       "        [[[0.2480, 0.2554, 0.2475, 0.2491],\n",
       "          [0.2504, 0.2567, 0.2520, 0.2409],\n",
       "          [0.2496, 0.2589, 0.2533, 0.2382],\n",
       "          [0.2494, 0.2466, 0.2393, 0.2647]],\n",
       "\n",
       "         [[0.2388, 0.2649, 0.2585, 0.2377],\n",
       "          [0.2403, 0.2640, 0.2705, 0.2252],\n",
       "          [0.2421, 0.2635, 0.2684, 0.2260],\n",
       "          [0.2420, 0.2643, 0.2620, 0.2318]]],\n",
       "\n",
       "\n",
       "        [[[0.2577, 0.2419, 0.2523, 0.2481],\n",
       "          [0.2391, 0.2655, 0.2468, 0.2486],\n",
       "          [0.2602, 0.2495, 0.2443, 0.2460],\n",
       "          [0.2421, 0.2585, 0.2507, 0.2487]],\n",
       "\n",
       "         [[0.2772, 0.2279, 0.2505, 0.2444],\n",
       "          [0.2673, 0.2322, 0.2538, 0.2467],\n",
       "          [0.2604, 0.2387, 0.2529, 0.2480],\n",
       "          [0.2609, 0.2401, 0.2512, 0.2478]]],\n",
       "\n",
       "\n",
       "        [[[0.2559, 0.2460, 0.2505, 0.2476],\n",
       "          [0.2531, 0.2473, 0.2478, 0.2518],\n",
       "          [0.2550, 0.2466, 0.2500, 0.2484],\n",
       "          [0.2504, 0.2485, 0.2477, 0.2534]],\n",
       "\n",
       "         [[0.2411, 0.2505, 0.2453, 0.2631],\n",
       "          [0.2457, 0.2496, 0.2473, 0.2573],\n",
       "          [0.2430, 0.2508, 0.2468, 0.2594],\n",
       "          [0.2393, 0.2514, 0.2449, 0.2644]]],\n",
       "\n",
       "\n",
       "        [[[0.2474, 0.2457, 0.2575, 0.2493],\n",
       "          [0.2514, 0.2423, 0.2566, 0.2496],\n",
       "          [0.2500, 0.2499, 0.2576, 0.2426],\n",
       "          [0.2472, 0.2414, 0.2481, 0.2632]],\n",
       "\n",
       "         [[0.2443, 0.2466, 0.2444, 0.2646],\n",
       "          [0.2518, 0.2494, 0.2416, 0.2573],\n",
       "          [0.2424, 0.2452, 0.2412, 0.2713],\n",
       "          [0.2357, 0.2426, 0.2392, 0.2825]]],\n",
       "\n",
       "\n",
       "        [[[0.2497, 0.2526, 0.2498, 0.2479],\n",
       "          [0.2482, 0.2500, 0.2512, 0.2507],\n",
       "          [0.2454, 0.2473, 0.2522, 0.2551],\n",
       "          [0.2423, 0.2524, 0.2560, 0.2494]],\n",
       "\n",
       "         [[0.2618, 0.2527, 0.2406, 0.2449],\n",
       "          [0.2589, 0.2526, 0.2369, 0.2516],\n",
       "          [0.2576, 0.2519, 0.2362, 0.2542],\n",
       "          [0.2612, 0.2530, 0.2405, 0.2453]]],\n",
       "\n",
       "\n",
       "        [[[0.2531, 0.2400, 0.2571, 0.2498],\n",
       "          [0.2485, 0.2477, 0.2546, 0.2491],\n",
       "          [0.2511, 0.2456, 0.2563, 0.2470],\n",
       "          [0.2547, 0.2344, 0.2629, 0.2480]],\n",
       "\n",
       "         [[0.2615, 0.2499, 0.2386, 0.2501],\n",
       "          [0.2556, 0.2498, 0.2438, 0.2508],\n",
       "          [0.2605, 0.2487, 0.2444, 0.2464],\n",
       "          [0.2579, 0.2518, 0.2416, 0.2487]]],\n",
       "\n",
       "\n",
       "        [[[0.2546, 0.2455, 0.2476, 0.2523],\n",
       "          [0.2508, 0.2485, 0.2494, 0.2513],\n",
       "          [0.2535, 0.2467, 0.2442, 0.2556],\n",
       "          [0.2517, 0.2474, 0.2558, 0.2451]],\n",
       "\n",
       "         [[0.2427, 0.2585, 0.2483, 0.2505],\n",
       "          [0.2409, 0.2612, 0.2481, 0.2498],\n",
       "          [0.2442, 0.2543, 0.2458, 0.2557],\n",
       "          [0.2415, 0.2621, 0.2508, 0.2455]]],\n",
       "\n",
       "\n",
       "        [[[0.2501, 0.2499, 0.2505, 0.2495],\n",
       "          [0.2579, 0.2467, 0.2541, 0.2412],\n",
       "          [0.2410, 0.2473, 0.2536, 0.2581],\n",
       "          [0.2466, 0.2454, 0.2561, 0.2519]],\n",
       "\n",
       "         [[0.2329, 0.2533, 0.2512, 0.2627],\n",
       "          [0.2315, 0.2496, 0.2506, 0.2683],\n",
       "          [0.2313, 0.2564, 0.2494, 0.2628],\n",
       "          [0.2297, 0.2508, 0.2499, 0.2695]]],\n",
       "\n",
       "\n",
       "        [[[0.2504, 0.2512, 0.2488, 0.2497],\n",
       "          [0.2490, 0.2440, 0.2570, 0.2499],\n",
       "          [0.2495, 0.2518, 0.2508, 0.2479],\n",
       "          [0.2502, 0.2550, 0.2458, 0.2490]],\n",
       "\n",
       "         [[0.2520, 0.2413, 0.2459, 0.2608],\n",
       "          [0.2512, 0.2397, 0.2470, 0.2621],\n",
       "          [0.2545, 0.2425, 0.2406, 0.2624],\n",
       "          [0.2527, 0.2419, 0.2446, 0.2608]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "F.softmax(temp, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.tensor([[[[0.4741, 0.4795, 0.4852, 0.4799],\n",
    "          [0.4767, 0.4818, 0.4878, 0.4824],\n",
    "          [0.4564, 0.4468, 0.4523, 0.4432],\n",
    "          [0.4691, 0.4691, 0.4759, 0.4696]],\n",
    "\n",
    "         [[0.5259, 0.5205, 0.5148, 0.5201],\n",
    "          [0.5233, 0.5182, 0.5122, 0.5176],\n",
    "          [0.5436, 0.5532, 0.5477, 0.5568],\n",
    "          [0.5309, 0.5309, 0.5241, 0.5304]]],\n",
    "\n",
    "\n",
    "        [[[0.4822, 0.4636, 0.4619, 0.4845],\n",
    "          [0.4435, 0.4266, 0.4161, 0.4501],\n",
    "          [0.4583, 0.4464, 0.4364, 0.4637],\n",
    "          [0.4601, 0.4355, 0.4302, 0.4856]],\n",
    "\n",
    "         [[0.5178, 0.5364, 0.5381, 0.5155],\n",
    "          [0.5565, 0.5734, 0.5839, 0.5499],\n",
    "          [0.5417, 0.5536, 0.5636, 0.5363],\n",
    "          [0.5399, 0.5645, 0.5698, 0.5144]]],\n",
    "\n",
    "\n",
    "        [[[0.4031, 0.4354, 0.4224, 0.4244],\n",
    "          [0.3934, 0.4533, 0.4135, 0.4223],\n",
    "          [0.4526, 0.4638, 0.4443, 0.4508],\n",
    "          [0.4177, 0.4542, 0.4355, 0.4369]],\n",
    "\n",
    "         [[0.5969, 0.5646, 0.5776, 0.5756],\n",
    "          [0.6066, 0.5467, 0.5865, 0.5777],\n",
    "          [0.5474, 0.5362, 0.5557, 0.5492],\n",
    "          [0.5823, 0.5458, 0.5645, 0.5631]]],\n",
    "\n",
    "\n",
    "        [[[0.4468, 0.4277, 0.4373, 0.4173],\n",
    "          [0.4691, 0.4594, 0.4622, 0.4563],\n",
    "          [0.4602, 0.4441, 0.4515, 0.4375],\n",
    "          [0.4539, 0.4398, 0.4455, 0.4322]],\n",
    "\n",
    "         [[0.5532, 0.5723, 0.5627, 0.5827],\n",
    "          [0.5309, 0.5406, 0.5378, 0.5437],\n",
    "          [0.5398, 0.5559, 0.5485, 0.5625],\n",
    "          [0.5461, 0.5602, 0.5545, 0.5678]]],\n",
    "\n",
    "\n",
    "        [[[0.4725, 0.4685, 0.4824, 0.4545],\n",
    "          [0.4388, 0.4321, 0.4542, 0.4318],\n",
    "          [0.4573, 0.4544, 0.4660, 0.4222],\n",
    "          [0.4519, 0.4390, 0.4492, 0.4228]],\n",
    "\n",
    "         [[0.5275, 0.5315, 0.5176, 0.5455],\n",
    "          [0.5612, 0.5679, 0.5458, 0.5682],\n",
    "          [0.5427, 0.5456, 0.5340, 0.5778],\n",
    "          [0.5481, 0.5610, 0.5508, 0.5772]]],\n",
    "\n",
    "\n",
    "        [[[0.4403, 0.4518, 0.4612, 0.4549],\n",
    "          [0.4550, 0.4628, 0.4800, 0.4645],\n",
    "          [0.4616, 0.4691, 0.4900, 0.4745],\n",
    "          [0.4201, 0.4379, 0.4539, 0.4426]],\n",
    "\n",
    "         [[0.5597, 0.5482, 0.5388, 0.5451],\n",
    "          [0.5450, 0.5372, 0.5200, 0.5355],\n",
    "          [0.5384, 0.5309, 0.5100, 0.5255],\n",
    "          [0.5799, 0.5621, 0.5461, 0.5574]]],\n",
    "\n",
    "\n",
    "        [[[0.4268, 0.4249, 0.4533, 0.4345],\n",
    "          [0.4436, 0.4483, 0.4612, 0.4488],\n",
    "          [0.4354, 0.4414, 0.4563, 0.4451],\n",
    "          [0.4521, 0.4374, 0.4762, 0.4543]],\n",
    "\n",
    "         [[0.5732, 0.5751, 0.5467, 0.5655],\n",
    "          [0.5564, 0.5517, 0.5388, 0.5512],\n",
    "          [0.5646, 0.5586, 0.5437, 0.5549],\n",
    "          [0.5479, 0.5626, 0.5238, 0.5457]]],\n",
    "\n",
    "\n",
    "        [[[0.4699, 0.4451, 0.4572, 0.4596],\n",
    "          [0.4687, 0.4464, 0.4600, 0.4602],\n",
    "          [0.4973, 0.4804, 0.4864, 0.4878],\n",
    "          [0.4446, 0.4202, 0.4391, 0.4339]],\n",
    "\n",
    "         [[0.5301, 0.5549, 0.5428, 0.5404],\n",
    "          [0.5313, 0.5536, 0.5400, 0.5398],\n",
    "          [0.5027, 0.5196, 0.5136, 0.5122],\n",
    "          [0.5554, 0.5798, 0.5609, 0.5661]]],\n",
    "\n",
    "\n",
    "        [[[0.4567, 0.4357, 0.4384, 0.4264],\n",
    "          [0.4305, 0.4014, 0.4075, 0.3789],\n",
    "          [0.4502, 0.4313, 0.4443, 0.4357],\n",
    "          [0.4326, 0.4100, 0.4212, 0.3989]],\n",
    "\n",
    "         [[0.5433, 0.5643, 0.5616, 0.5736],\n",
    "          [0.5695, 0.5986, 0.5925, 0.6211],\n",
    "          [0.5498, 0.5687, 0.5557, 0.5643],\n",
    "          [0.5674, 0.5900, 0.5788, 0.6011]]],\n",
    "\n",
    "\n",
    "        [[[0.4318, 0.4433, 0.4363, 0.4227],\n",
    "          [0.4588, 0.4654, 0.4709, 0.4492],\n",
    "          [0.4256, 0.4398, 0.4407, 0.4167],\n",
    "          [0.4201, 0.4355, 0.4238, 0.4113]],\n",
    "\n",
    "         [[0.5682, 0.5567, 0.5637, 0.5773],\n",
    "          [0.5412, 0.5346, 0.5291, 0.5508],\n",
    "          [0.5744, 0.5602, 0.5593, 0.5833],\n",
    "          [0.5799, 0.5645, 0.5762, 0.5887]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: tensor([[[[ 2.1788e-02,  2.4740e-02,  4.6428e-02,  2.4802e-02],\n",
      "          [ 9.7510e-03,  1.2439e-02,  3.5460e-02,  1.4968e-02],\n",
      "          [ 3.1569e-02,  7.9339e-03, -2.2924e-03,  1.1331e-03],\n",
      "          [ 2.3694e-02,  2.3631e-02,  3.9638e-02,  2.2374e-02]],\n",
      "\n",
      "         [[ 1.2537e-01,  1.0683e-01,  1.0554e-01,  1.0506e-01],\n",
      "          [ 1.0300e-01,  8.5335e-02,  8.4349e-02,  8.5436e-02],\n",
      "          [ 2.0658e-01,  2.2153e-01,  1.8907e-01,  2.2919e-01],\n",
      "          [ 1.4749e-01,  1.4746e-01,  1.3614e-01,  1.4399e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6531e-02,  4.6004e-02,  1.4361e-02,  2.1016e-02],\n",
      "          [ 3.1137e-02,  5.6010e-02,  3.7463e-02, -7.4020e-03],\n",
      "          [ 4.5790e-02,  8.2320e-02,  6.0429e-02, -1.2206e-03],\n",
      "          [-4.7968e-02, -5.9232e-02, -8.9583e-02,  1.1392e-02]],\n",
      "\n",
      "         [[ 8.7872e-02,  1.9167e-01,  1.6725e-01,  8.3198e-02],\n",
      "          [ 2.5791e-01,  3.5175e-01,  3.7615e-01,  1.9301e-01],\n",
      "          [ 2.1294e-01,  2.9759e-01,  3.1604e-01,  1.4411e-01],\n",
      "          [ 1.1194e-01,  2.0009e-01,  1.9151e-01,  6.9000e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8831e-02, -3.4303e-02,  7.5190e-03, -9.3699e-03],\n",
      "          [-1.4929e-01, -4.4830e-02, -1.1775e-01, -1.1034e-01],\n",
      "          [ 6.9188e-03, -3.5093e-02, -5.6029e-02, -4.9418e-02],\n",
      "          [-1.2338e-01, -5.7830e-02, -8.8388e-02, -9.6598e-02]],\n",
      "\n",
      "         [[ 4.2135e-01,  2.2549e-01,  3.2025e-01,  2.9554e-01],\n",
      "          [ 2.8358e-01,  1.4263e-01,  2.3161e-01,  2.0310e-01],\n",
      "          [ 1.9689e-01,  1.0992e-01,  1.6779e-01,  1.4817e-01],\n",
      "          [ 2.0877e-01,  1.2573e-01,  1.7105e-01,  1.5721e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8856e-02, -5.8313e-02, -4.0485e-02, -5.1952e-02],\n",
      "          [-7.0528e-03, -3.0407e-02, -2.8235e-02, -1.2277e-02],\n",
      "          [-1.8420e-02, -5.1930e-02, -3.8346e-02, -4.4876e-02],\n",
      "          [ 2.0212e-02,  1.2526e-02,  9.1663e-03,  3.2063e-02]],\n",
      "\n",
      "         [[ 1.9455e-01,  2.3308e-01,  2.1183e-01,  2.8207e-01],\n",
      "          [ 1.1682e-01,  1.3248e-01,  1.2324e-01,  1.6298e-01],\n",
      "          [ 1.4111e-01,  1.7247e-01,  1.5642e-01,  2.0633e-01],\n",
      "          [ 2.0509e-01,  2.5463e-01,  2.2816e-01,  3.0481e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8240e-02, -3.5101e-02,  1.1787e-02, -2.0791e-02],\n",
      "          [-7.7259e-02, -1.1400e-01, -5.6630e-02, -8.4240e-02],\n",
      "          [-3.6651e-02, -3.7082e-02, -6.6445e-03, -6.6776e-02],\n",
      "          [-3.8467e-04, -2.3927e-02,  3.4124e-03,  6.2404e-02]],\n",
      "\n",
      "         [[ 8.1809e-02,  9.1113e-02,  8.2271e-02,  1.6172e-01],\n",
      "          [ 1.6876e-01,  1.5928e-01,  1.2727e-01,  1.9024e-01],\n",
      "          [ 1.3451e-01,  1.4591e-01,  1.2945e-01,  2.4699e-01],\n",
      "          [ 1.9256e-01,  2.2132e-01,  2.0735e-01,  3.7369e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4803e-03,  1.7835e-02,  6.8059e-03, -1.1012e-03],\n",
      "          [-1.7261e-02, -9.9426e-03, -5.2170e-03, -7.2963e-03],\n",
      "          [-4.2320e-02, -3.4397e-02, -1.5060e-02, -3.6030e-03],\n",
      "          [-7.6403e-02, -3.5465e-02, -2.1455e-02, -4.7410e-02]],\n",
      "\n",
      "         [[ 2.4663e-01,  2.1127e-01,  1.6221e-01,  1.7987e-01],\n",
      "          [ 1.6343e-01,  1.3907e-01,  7.4655e-02,  1.3508e-01],\n",
      "          [ 1.1157e-01,  8.9201e-02,  2.4874e-02,  9.8355e-02],\n",
      "          [ 2.4614e-01,  2.1426e-01,  1.6338e-01,  1.8316e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7761e-02, -1.5390e-02,  5.3641e-02,  2.4712e-02],\n",
      "          [-5.9217e-02, -6.2658e-02, -3.4971e-02, -5.6932e-02],\n",
      "          [-8.1622e-03, -3.0511e-02,  1.2470e-02, -2.4792e-02],\n",
      "          [ 4.8666e-02, -3.4740e-02,  8.0378e-02,  2.1652e-02]],\n",
      "\n",
      "         [[ 3.3258e-01,  2.8715e-01,  2.4103e-01,  2.8805e-01],\n",
      "          [ 1.6748e-01,  1.4483e-01,  1.2050e-01,  1.4872e-01],\n",
      "          [ 2.5149e-01,  2.0501e-01,  1.8763e-01,  1.9584e-01],\n",
      "          [ 2.4103e-01,  2.1712e-01,  1.7553e-01,  2.0477e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9530e-03, -3.9589e-02, -3.0890e-02, -1.2264e-02],\n",
      "          [ 3.4042e-02,  2.4668e-02,  2.8282e-02,  3.6050e-02],\n",
      "          [ 4.0340e-02,  1.3287e-02,  3.2564e-03,  4.8535e-02],\n",
      "          [-4.7881e-02, -6.4979e-02, -3.1962e-02, -7.4571e-02]],\n",
      "\n",
      "         [[ 1.1763e-01,  1.8100e-01,  1.4059e-01,  1.4958e-01],\n",
      "          [ 1.5935e-01,  2.4003e-01,  1.8880e-01,  1.9547e-01],\n",
      "          [ 5.1315e-02,  9.1847e-02,  5.7663e-02,  9.7304e-02],\n",
      "          [ 1.7480e-01,  2.5679e-01,  2.1270e-01,  1.9144e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1852e-02,  1.0980e-02,  1.3514e-02,  9.6837e-03],\n",
      "          [-2.6517e-02, -7.0835e-02, -4.1514e-02, -9.3447e-02],\n",
      "          [ 4.9624e-02,  7.5706e-02,  1.0075e-01,  1.1846e-01],\n",
      "          [ 2.3493e-02,  1.8705e-02,  6.1188e-02,  4.4703e-02]],\n",
      "\n",
      "         [[ 1.8558e-01,  2.6971e-01,  2.6129e-01,  3.0618e-01],\n",
      "          [ 2.5311e-01,  3.2860e-01,  3.3259e-01,  4.0066e-01],\n",
      "          [ 2.4931e-01,  3.5224e-01,  3.2448e-01,  3.7693e-01],\n",
      "          [ 2.9484e-01,  3.8281e-01,  3.7918e-01,  4.5458e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8009e-02, -1.4777e-02, -2.4200e-02, -2.0843e-02],\n",
      "          [ 5.9653e-02,  3.9410e-02,  9.1368e-02,  6.3346e-02],\n",
      "          [-8.3143e-03,  1.0372e-03, -3.1082e-03, -1.4487e-02],\n",
      "          [-3.9325e-02, -2.0189e-02, -5.6797e-02, -4.3959e-02]],\n",
      "\n",
      "         [[ 2.5636e-01,  2.1312e-01,  2.3217e-01,  2.9097e-01],\n",
      "          [ 2.2494e-01,  1.7809e-01,  2.0780e-01,  2.6733e-01],\n",
      "          [ 2.9140e-01,  2.4297e-01,  2.3523e-01,  3.2167e-01],\n",
      "          [ 2.8300e-01,  2.3938e-01,  2.5044e-01,  3.1454e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "SHAPE: torch.Size([10, 2, 4, 4]) \n",
      "tensor([[[[0.4741, 0.4795, 0.4852, 0.4799],\n",
      "          [0.4767, 0.4818, 0.4878, 0.4824],\n",
      "          [0.4564, 0.4468, 0.4523, 0.4432],\n",
      "          [0.4691, 0.4691, 0.4759, 0.4696]],\n",
      "\n",
      "         [[0.5259, 0.5205, 0.5148, 0.5201],\n",
      "          [0.5233, 0.5182, 0.5122, 0.5176],\n",
      "          [0.5436, 0.5532, 0.5477, 0.5568],\n",
      "          [0.5309, 0.5309, 0.5241, 0.5304]]],\n",
      "\n",
      "\n",
      "        [[[0.4822, 0.4636, 0.4619, 0.4845],\n",
      "          [0.4435, 0.4266, 0.4161, 0.4501],\n",
      "          [0.4583, 0.4464, 0.4364, 0.4637],\n",
      "          [0.4601, 0.4355, 0.4302, 0.4856]],\n",
      "\n",
      "         [[0.5178, 0.5364, 0.5381, 0.5155],\n",
      "          [0.5565, 0.5734, 0.5839, 0.5499],\n",
      "          [0.5417, 0.5536, 0.5636, 0.5363],\n",
      "          [0.5399, 0.5645, 0.5698, 0.5144]]],\n",
      "\n",
      "\n",
      "        [[[0.4031, 0.4354, 0.4224, 0.4244],\n",
      "          [0.3934, 0.4533, 0.4135, 0.4223],\n",
      "          [0.4526, 0.4638, 0.4443, 0.4508],\n",
      "          [0.4177, 0.4542, 0.4355, 0.4369]],\n",
      "\n",
      "         [[0.5969, 0.5646, 0.5776, 0.5756],\n",
      "          [0.6066, 0.5467, 0.5865, 0.5777],\n",
      "          [0.5474, 0.5362, 0.5557, 0.5492],\n",
      "          [0.5823, 0.5458, 0.5645, 0.5631]]],\n",
      "\n",
      "\n",
      "        [[[0.4468, 0.4277, 0.4373, 0.4173],\n",
      "          [0.4691, 0.4594, 0.4622, 0.4563],\n",
      "          [0.4602, 0.4441, 0.4515, 0.4375],\n",
      "          [0.4539, 0.4398, 0.4455, 0.4322]],\n",
      "\n",
      "         [[0.5532, 0.5723, 0.5627, 0.5827],\n",
      "          [0.5309, 0.5406, 0.5378, 0.5437],\n",
      "          [0.5398, 0.5559, 0.5485, 0.5625],\n",
      "          [0.5461, 0.5602, 0.5545, 0.5678]]],\n",
      "\n",
      "\n",
      "        [[[0.4725, 0.4685, 0.4824, 0.4545],\n",
      "          [0.4388, 0.4321, 0.4542, 0.4318],\n",
      "          [0.4573, 0.4544, 0.4660, 0.4222],\n",
      "          [0.4519, 0.4390, 0.4492, 0.4228]],\n",
      "\n",
      "         [[0.5275, 0.5315, 0.5176, 0.5455],\n",
      "          [0.5612, 0.5679, 0.5458, 0.5682],\n",
      "          [0.5427, 0.5456, 0.5340, 0.5778],\n",
      "          [0.5481, 0.5610, 0.5508, 0.5772]]],\n",
      "\n",
      "\n",
      "        [[[0.4403, 0.4518, 0.4612, 0.4549],\n",
      "          [0.4550, 0.4628, 0.4800, 0.4645],\n",
      "          [0.4616, 0.4691, 0.4900, 0.4745],\n",
      "          [0.4201, 0.4379, 0.4539, 0.4426]],\n",
      "\n",
      "         [[0.5597, 0.5482, 0.5388, 0.5451],\n",
      "          [0.5450, 0.5372, 0.5200, 0.5355],\n",
      "          [0.5384, 0.5309, 0.5100, 0.5255],\n",
      "          [0.5799, 0.5621, 0.5461, 0.5574]]],\n",
      "\n",
      "\n",
      "        [[[0.4268, 0.4249, 0.4533, 0.4345],\n",
      "          [0.4436, 0.4483, 0.4612, 0.4488],\n",
      "          [0.4354, 0.4414, 0.4563, 0.4451],\n",
      "          [0.4521, 0.4374, 0.4762, 0.4543]],\n",
      "\n",
      "         [[0.5732, 0.5751, 0.5467, 0.5655],\n",
      "          [0.5564, 0.5517, 0.5388, 0.5512],\n",
      "          [0.5646, 0.5586, 0.5437, 0.5549],\n",
      "          [0.5479, 0.5626, 0.5238, 0.5457]]],\n",
      "\n",
      "\n",
      "        [[[0.4699, 0.4451, 0.4572, 0.4596],\n",
      "          [0.4687, 0.4464, 0.4600, 0.4602],\n",
      "          [0.4973, 0.4804, 0.4864, 0.4878],\n",
      "          [0.4446, 0.4202, 0.4391, 0.4339]],\n",
      "\n",
      "         [[0.5301, 0.5549, 0.5428, 0.5404],\n",
      "          [0.5313, 0.5536, 0.5400, 0.5398],\n",
      "          [0.5027, 0.5196, 0.5136, 0.5122],\n",
      "          [0.5554, 0.5798, 0.5609, 0.5661]]],\n",
      "\n",
      "\n",
      "        [[[0.4567, 0.4357, 0.4384, 0.4264],\n",
      "          [0.4305, 0.4014, 0.4075, 0.3789],\n",
      "          [0.4502, 0.4313, 0.4443, 0.4357],\n",
      "          [0.4326, 0.4100, 0.4212, 0.3989]],\n",
      "\n",
      "         [[0.5433, 0.5643, 0.5616, 0.5736],\n",
      "          [0.5695, 0.5986, 0.5925, 0.6211],\n",
      "          [0.5498, 0.5687, 0.5557, 0.5643],\n",
      "          [0.5674, 0.5900, 0.5788, 0.6011]]],\n",
      "\n",
      "\n",
      "        [[[0.4318, 0.4433, 0.4363, 0.4227],\n",
      "          [0.4588, 0.4654, 0.4709, 0.4492],\n",
      "          [0.4256, 0.4398, 0.4407, 0.4167],\n",
      "          [0.4201, 0.4355, 0.4238, 0.4113]],\n",
      "\n",
      "         [[0.5682, 0.5567, 0.5637, 0.5773],\n",
      "          [0.5412, 0.5346, 0.5291, 0.5508],\n",
      "          [0.5744, 0.5602, 0.5593, 0.5833],\n",
      "          [0.5799, 0.5645, 0.5762, 0.5887]]]], grad_fn=<SoftmaxBackward>)\n",
      "..\\attention.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(self.d_model)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "encoder(rands).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "masked_fill() received an invalid combination of arguments - got (mask=Tensor, value=int, ), but expected one of:\n * (Tensor input, Tensor mask, Tensor value)\n * (Tensor input, Tensor mask, Number value)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-76d818f9dd80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: masked_fill() received an invalid combination of arguments - got (mask=Tensor, value=int, ), but expected one of:\n * (Tensor input, Tensor mask, Tensor value)\n * (Tensor input, Tensor mask, Number value)\n"
     ]
    }
   ],
   "source": [
    "torch.masked_fill(mask=mask, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tril(torch.ones(4,4), diagonal=0).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "pad_id = 0\n",
    "vocab_size = 100\n",
    "max_len = 10\n",
    "hidden_dim = 6\n",
    "\n",
    "def padding(data: list, pad_id: int=0) -> (list, int):\n",
    "    max_len = len(max(data, key=len))\n",
    "    output = [sample + [pad_id]*(max_len-len(sample)) for sample in tqdm(data)]\n",
    "    return output, max_len\n",
    "\n",
    "data = [\n",
    "     [62, 13, 47, 39, 78, 33, 56, 13, 39, 29],\n",
    "     [60, 96, 51, 32, 90, 44, 86, 71, 36, 18],\n",
    "     [35, 45, 48, 65, 91, 99, 92, 10, 31, 21],\n",
    "     [75, 51, 45, 48, 65, 91, 99, 11, 13, 28],\n",
    "     [66, 88, 98, 47, 48, 65, 17, 13, 67, 99],\n",
    "     ]\n",
    "\n",
    "# data, max_len = padding(data)\n",
    "data = torch.LongTensor(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weight initialized\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=hidden_dim)\n",
    "embedding.weight.data.uniform_(-1, 1)\n",
    "print('Weight initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_embedded = embedding(data)\n",
    "X_embedded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_query = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Query\n",
    "w_key = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Key\n",
    "w_value = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Value\n",
    "\n",
    "query = w_query(X_embedded)\n",
    "key = w_key(X_embedded)\n",
    "value = w_value(X_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MultiHeadAttention(hidden_dim=hidden_dim, num_heads=2)\n",
    "attention_mat = attention(query, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "attention_mat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layer_norm = nn.LayerNorm(normalized_shape=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "attention_mat.size()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "attn_layer_norm(attention_mat).size()"
   ]
  }
 ]
}