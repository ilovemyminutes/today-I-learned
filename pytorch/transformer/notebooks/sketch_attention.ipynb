{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('py36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e4583e3e051816b4ac89cf1b6baba6f81196736b754b6f0341f1424c68064e5b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from attention import MultiHeadAttention\n",
    "from encoder import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 6\n",
    "NUM_HEADS = 2\n",
    "MAX_LEN = 4\n",
    "BATCH_SIZE = 5\n",
    "encoder = Encoder(d_model=6, num_heads=2, max_len=4)\n",
    "sample_batch = torch.rand(10, 4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layer = MultiHeadAttention(d_model=D_MODEL, num_heads=NUM_HEADS, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = torch.rand(BATCH_SIZE, MAX_LEN, D_MODEL)\n",
    "key = torch.rand(BATCH_SIZE, MAX_LEN, D_MODEL)\n",
    "value = torch.rand(BATCH_SIZE, MAX_LEN, D_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query.view(BATCH_SIZE, -1, NUM_HEADS, D_MODEL // NUM_HEADS)\n",
    "key = key.view(BATCH_SIZE, -1, NUM_HEADS, D_MODEL // NUM_HEADS)\n",
    "value = value.view(BATCH_SIZE, -1, NUM_HEADS, D_MODEL // NUM_HEADS)\n",
    "query = query.transpose(1, 2)\n",
    "key = key.transpose(1, 2)\n",
    "value = value.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "attention_raw = F.softmax(\n",
    "    torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(D_MODEL), dim=-1\n",
    ")\n",
    "attention_raw.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "attention_raw.size()[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [False, False,  True,  True],\n",
       "        [False, False, False,  True],\n",
       "        [False, False, False, False]])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(4,4), diagonal=1).bool()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5024, 0.4976, 0.0000, 0.0000],\n",
       "          [0.3337, 0.3322, 0.3340, 0.0000],\n",
       "          [0.2446, 0.2492, 0.2455, 0.2607]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4960, 0.5040, 0.0000, 0.0000],\n",
       "          [0.3316, 0.3362, 0.3322, 0.0000],\n",
       "          [0.2435, 0.2456, 0.2418, 0.2691]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4799, 0.5201, 0.0000, 0.0000],\n",
       "          [0.3257, 0.3425, 0.3318, 0.0000],\n",
       "          [0.2407, 0.2599, 0.2457, 0.2537]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4972, 0.5028, 0.0000, 0.0000],\n",
       "          [0.3361, 0.3287, 0.3352, 0.0000],\n",
       "          [0.2524, 0.2487, 0.2521, 0.2469]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5083, 0.4917, 0.0000, 0.0000],\n",
       "          [0.3363, 0.3234, 0.3404, 0.0000],\n",
       "          [0.2520, 0.2488, 0.2558, 0.2434]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4999, 0.5001, 0.0000, 0.0000],\n",
       "          [0.3283, 0.3362, 0.3355, 0.0000],\n",
       "          [0.2452, 0.2476, 0.2510, 0.2562]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5171, 0.4829, 0.0000, 0.0000],\n",
       "          [0.3414, 0.3248, 0.3338, 0.0000],\n",
       "          [0.2556, 0.2452, 0.2495, 0.2497]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4969, 0.5031, 0.0000, 0.0000],\n",
       "          [0.3314, 0.3349, 0.3337, 0.0000],\n",
       "          [0.2393, 0.2420, 0.2500, 0.2687]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4818, 0.5182, 0.0000, 0.0000],\n",
       "          [0.3209, 0.3511, 0.3280, 0.0000],\n",
       "          [0.2442, 0.2574, 0.2523, 0.2462]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5010, 0.4990, 0.0000, 0.0000],\n",
       "          [0.3420, 0.3293, 0.3287, 0.0000],\n",
       "          [0.2557, 0.2481, 0.2448, 0.2514]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "F.softmax(attn_masked, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "pad_id = 0\n",
    "vocab_size = 100\n",
    "max_len = 10\n",
    "hidden_dim = 6\n",
    "\n",
    "def padding(data: list, pad_id: int=0) -> (list, int):\n",
    "    max_len = len(max(data, key=len))\n",
    "    output = [sample + [pad_id]*(max_len-len(sample)) for sample in tqdm(data)]\n",
    "    return output, max_len\n",
    "\n",
    "data = [\n",
    "     [62, 13, 47, 39, 78, 33, 56, 13, 39, 29],\n",
    "     [60, 96, 51, 32, 90, 44, 86, 71, 36, 18],\n",
    "     [35, 45, 48, 65, 91, 99, 92, 10, 31, 21],\n",
    "     [75, 51, 45, 48, 65, 91, 99, 11, 13, 28],\n",
    "     [66, 88, 98, 47, 48, 65, 17, 13, 67, 99],\n",
    "     ]\n",
    "\n",
    "# data, max_len = padding(data)\n",
    "data = torch.LongTensor(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weight initialized\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=hidden_dim)\n",
    "embedding.weight.data.uniform_(-1, 1)\n",
    "print('Weight initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_embedded = embedding(data)\n",
    "X_embedded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_query = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Query\n",
    "w_key = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Key\n",
    "w_value = nn.Linear(in_features=hidden_dim, out_features=hidden_dim) # Value\n",
    "\n",
    "query = w_query(X_embedded)\n",
    "key = w_key(X_embedded)\n",
    "value = w_value(X_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MultiHeadAttention(hidden_dim=hidden_dim, num_heads=2)\n",
    "attention_mat = attention(query, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "attention_mat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layer_norm = nn.LayerNorm(normalized_shape=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "attention_mat.size()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "attn_layer_norm(attention_mat).size()"
   ]
  }
 ]
}